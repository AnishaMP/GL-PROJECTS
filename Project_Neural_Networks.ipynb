{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "i7ucv75deNj_",
    "outputId": "259482e0-71b0-49a0-ad6e-01f91320bf74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
      "You set: `2.x]`. This will be interpreted as: `2.x`.\n",
      "\n",
      "\n",
      "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorflow_version 2.x]\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JQvufe6SkU1"
   },
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6jU1vFsexoE"
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers, regularizers\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lqTit7ung55p"
   },
   "source": [
    "#Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DLwyfsEg5MG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Cz_ImBYIWXpw",
    "outputId": "e7bdfb7f-23b5-47ec-82cf-4219d13b526f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxJTdTKRi_hm"
   },
   "outputs": [],
   "source": [
    "#Opening file as read only\n",
    "data_SVHN = h5py.File('/content/drive/My Drive/GL dataset/SVHN_single_grey1.h5' , 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7YmKFtXDa7Og"
   },
   "outputs": [],
   "source": [
    "#Loading train, test and validation set\n",
    "X_train = data_SVHN  ['X_train'][:]\n",
    "y_train = data_SVHN ['y_train'][:]\n",
    "\n",
    "X_test = data_SVHN ['X_test'] [:]\n",
    "y_test = data_SVHN ['y_test'][:]        \n",
    "\n",
    "X_val = data_SVHN ['X_val'] [:]\n",
    "y_val = data_SVHN ['y_val'] [:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DvNEA903cm-M",
    "outputId": "2cd96d47-7bef-474b-b41f-8423d75afe29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method File.close of <HDF5 file \"SVHN_single_grey1.h5\" (mode r)>>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Close the file\n",
    "data_SVHN.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYEeqVDXj3HA"
   },
   "source": [
    "#Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "qQmoC4_9Rp45",
    "outputId": "09c14e0b-318d-4630-f6e3-dce3631e8cce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<HDF5 dataset \"X_test\": shape (18000, 32, 32), type \"<f4\">,\n",
       " <HDF5 dataset \"X_train\": shape (42000, 32, 32), type \"<f4\">,\n",
       " <HDF5 dataset \"X_val\": shape (60000, 32, 32), type \"<f4\">,\n",
       " <HDF5 dataset \"y_test\": shape (18000,), type \"|u1\">,\n",
       " <HDF5 dataset \"y_train\": shape (42000,), type \"|u1\">,\n",
       " <HDF5 dataset \"y_val\": shape (60000,), type \"|u1\">]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_SVHN.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "UQm79VCiX4re",
    "outputId": "33efba96-c921-4396-c438-1c7018bbceaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train is  (42000, 32, 32)\n",
      "Shape of y_train is  (42000,)\n",
      "Shape of X_test is  (18000, 32, 32)\n",
      "Shape of y_test is  (18000,)\n",
      "Shape of X_val is  (60000, 32, 32)\n",
      "Shape of y_val is  (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train is ', X_train.shape)\n",
    "print('Shape of y_train is ', y_train.shape)\n",
    "print('Shape of X_test is ', X_test.shape)\n",
    "print('Shape of y_test is ', y_test.shape)\n",
    "print('Shape of X_val is ', X_val.shape)\n",
    "print('Shape of y_val is ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "9alMyrT7YN5W",
    "outputId": "391367a8-755a-45a8-fc39-bbde3c67a158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f624d8e7da0>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualising using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"Label: {}\".format(y_train[1]))\n",
    "plt.imshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "MhOljjcheJvX",
    "outputId": "1636481d-8de0-46e8-c2c6-232923b864ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the below image: 2\n",
      "label for each of the below image: 6\n",
      "label for each of the below image: 7\n",
      "label for each of the below image: 4\n",
      "label for each of the below image: 4\n",
      "label for each of the below image: 0\n",
      "label for each of the below image: 3\n",
      "label for each of the below image: 0\n",
      "label for each of the below image: 7\n",
      "label for each of the below image: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.axis('off')\n",
    "    print('label for each of the below image: %s' % (y_train[0:10][i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "eDpQAWGSyPy8",
    "outputId": "72770bde-1f73-4e60-f2f1-7af515a351bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(60000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "#Reshaping\n",
    "X_train = X_train.reshape(42000, 1024)\n",
    "print(X_train.shape)\n",
    "X_val = X_val.reshape(60000, 1024)\n",
    "print(X_val.shape)\n",
    "X_test = X_test.reshape(18000, 1024)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9G2ke6EkGkw"
   },
   "source": [
    "#Normalizing the images and Hot encoding target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Cqjr0sDj0_zC",
    "outputId": "9b21fabd-2911-406f-e8c7-5bcf3aac721f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254.9745\n",
      "0.0\n",
      "0.9999\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Normalising from 0-255 to 0-1\n",
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5IuOuqMO0_3P",
    "outputId": "ff4216a5-9adb-468f-82f3-0d0a5ad0ef69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024) (60000, 1024) (18000, 1024) (42000,) (60000,) (18000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Pn3PpKww1mcg",
    "outputId": "56f58798-9fe3-45e4-f457-a3337ecbdb12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#One-hot encoding class vector\n",
    "print(y_train[10])\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_val = tensorflow.keras.utils.to_categorical(y_val, num_classes=10)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ObobVxTKiMGT"
   },
   "source": [
    "#Building the NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0mAGWexRkRdM"
   },
   "source": [
    "1. Simple NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azZo4mIYl1eV"
   },
   "source": [
    "Building a model with 5 layers : 4 layers with 50 neurons and one output layer with 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6XzUJTL1vHC"
   },
   "outputs": [],
   "source": [
    "#Building the simple NN model\n",
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(50, input_shape = (1024, )))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "v3taaQEmI4TN",
    "outputId": "d992ea9e-fdde-47e7-8e7b-51d4daff3fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.3052 - accuracy: 0.1033 - val_loss: 2.3022 - val_accuracy: 0.1094\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.3009 - accuracy: 0.1095 - val_loss: 2.3000 - val_accuracy: 0.1111\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2993 - accuracy: 0.1110 - val_loss: 2.2987 - val_accuracy: 0.1107\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2981 - accuracy: 0.1134 - val_loss: 2.2976 - val_accuracy: 0.1196\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2969 - accuracy: 0.1225 - val_loss: 2.2965 - val_accuracy: 0.1241\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2958 - accuracy: 0.1271 - val_loss: 2.2953 - val_accuracy: 0.1312\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2945 - accuracy: 0.1332 - val_loss: 2.2939 - val_accuracy: 0.1353\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 3s 3ms/step - loss: 2.2931 - accuracy: 0.1382 - val_loss: 2.2924 - val_accuracy: 0.1436\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2914 - accuracy: 0.1465 - val_loss: 2.2906 - val_accuracy: 0.1493\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2894 - accuracy: 0.1537 - val_loss: 2.2884 - val_accuracy: 0.1594\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2871 - accuracy: 0.1634 - val_loss: 2.2860 - val_accuracy: 0.1676\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2843 - accuracy: 0.1704 - val_loss: 2.2831 - val_accuracy: 0.1756\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2811 - accuracy: 0.1834 - val_loss: 2.2795 - val_accuracy: 0.1855\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 3s 3ms/step - loss: 2.2774 - accuracy: 0.1925 - val_loss: 2.2756 - val_accuracy: 0.1972\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2730 - accuracy: 0.1997 - val_loss: 2.2707 - val_accuracy: 0.2069\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2679 - accuracy: 0.2083 - val_loss: 2.2651 - val_accuracy: 0.2104\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2617 - accuracy: 0.2147 - val_loss: 2.2582 - val_accuracy: 0.2175\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2543 - accuracy: 0.2206 - val_loss: 2.2501 - val_accuracy: 0.2227\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2456 - accuracy: 0.2245 - val_loss: 2.2409 - val_accuracy: 0.2278\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2353 - accuracy: 0.2316 - val_loss: 2.2292 - val_accuracy: 0.2341\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2229 - accuracy: 0.2374 - val_loss: 2.2160 - val_accuracy: 0.2408\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2083 - accuracy: 0.2455 - val_loss: 2.1997 - val_accuracy: 0.2522\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.1908 - accuracy: 0.2535 - val_loss: 2.1808 - val_accuracy: 0.2496\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 3s 3ms/step - loss: 2.1699 - accuracy: 0.2608 - val_loss: 2.1577 - val_accuracy: 0.2643\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.1444 - accuracy: 0.2687 - val_loss: 2.1298 - val_accuracy: 0.2704\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.1148 - accuracy: 0.2765 - val_loss: 2.0975 - val_accuracy: 0.2841\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.0811 - accuracy: 0.2861 - val_loss: 2.0619 - val_accuracy: 0.2938\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.0439 - accuracy: 0.2970 - val_loss: 2.0230 - val_accuracy: 0.3029\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 3s 3ms/step - loss: 2.0045 - accuracy: 0.3057 - val_loss: 1.9826 - val_accuracy: 0.3119\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.9647 - accuracy: 0.3157 - val_loss: 1.9424 - val_accuracy: 0.3216\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.9255 - accuracy: 0.3240 - val_loss: 1.9050 - val_accuracy: 0.3304\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.8891 - accuracy: 0.3305 - val_loss: 1.8700 - val_accuracy: 0.3363\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.8553 - accuracy: 0.3375 - val_loss: 1.8417 - val_accuracy: 0.3395\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.8254 - accuracy: 0.3424 - val_loss: 1.8091 - val_accuracy: 0.3467\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.7990 - accuracy: 0.3501 - val_loss: 1.7844 - val_accuracy: 0.3539\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.7750 - accuracy: 0.3541 - val_loss: 1.7641 - val_accuracy: 0.3590\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.7548 - accuracy: 0.3616 - val_loss: 1.7430 - val_accuracy: 0.3656\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.7360 - accuracy: 0.3665 - val_loss: 1.7236 - val_accuracy: 0.3735\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.7195 - accuracy: 0.3742 - val_loss: 1.7096 - val_accuracy: 0.3785\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.7047 - accuracy: 0.3785 - val_loss: 1.6945 - val_accuracy: 0.3843\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6904 - accuracy: 0.3857 - val_loss: 1.6922 - val_accuracy: 0.3847\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6773 - accuracy: 0.3893 - val_loss: 1.6677 - val_accuracy: 0.3958\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6646 - accuracy: 0.3975 - val_loss: 1.6540 - val_accuracy: 0.4038\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6531 - accuracy: 0.4055 - val_loss: 1.6481 - val_accuracy: 0.4090\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6412 - accuracy: 0.4119 - val_loss: 1.6325 - val_accuracy: 0.4182\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6291 - accuracy: 0.4185 - val_loss: 1.6227 - val_accuracy: 0.4234\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6180 - accuracy: 0.4262 - val_loss: 1.6102 - val_accuracy: 0.4292\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6061 - accuracy: 0.4314 - val_loss: 1.5985 - val_accuracy: 0.4374\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5953 - accuracy: 0.4373 - val_loss: 1.5906 - val_accuracy: 0.4403\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5838 - accuracy: 0.4451 - val_loss: 1.5776 - val_accuracy: 0.4490\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5730 - accuracy: 0.4517 - val_loss: 1.5606 - val_accuracy: 0.4525\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5613 - accuracy: 0.4585 - val_loss: 1.5523 - val_accuracy: 0.4629\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5499 - accuracy: 0.4639 - val_loss: 1.5373 - val_accuracy: 0.4713\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5387 - accuracy: 0.4706 - val_loss: 1.5257 - val_accuracy: 0.4782\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5274 - accuracy: 0.4767 - val_loss: 1.5323 - val_accuracy: 0.4740\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5162 - accuracy: 0.4828 - val_loss: 1.5124 - val_accuracy: 0.4832\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5047 - accuracy: 0.4883 - val_loss: 1.4944 - val_accuracy: 0.4925\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4932 - accuracy: 0.4922 - val_loss: 1.4796 - val_accuracy: 0.5016\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4818 - accuracy: 0.5005 - val_loss: 1.4719 - val_accuracy: 0.5046\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4702 - accuracy: 0.5060 - val_loss: 1.4622 - val_accuracy: 0.5105\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4586 - accuracy: 0.5117 - val_loss: 1.4465 - val_accuracy: 0.5163\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 3s 3ms/step - loss: 1.4460 - accuracy: 0.5191 - val_loss: 1.4450 - val_accuracy: 0.5169\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4338 - accuracy: 0.5225 - val_loss: 1.4283 - val_accuracy: 0.5263\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4217 - accuracy: 0.5290 - val_loss: 1.4199 - val_accuracy: 0.5256\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.4086 - accuracy: 0.5339 - val_loss: 1.3996 - val_accuracy: 0.5361\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3968 - accuracy: 0.5390 - val_loss: 1.3996 - val_accuracy: 0.5372\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3840 - accuracy: 0.5439 - val_loss: 1.3765 - val_accuracy: 0.5497\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3715 - accuracy: 0.5478 - val_loss: 1.3629 - val_accuracy: 0.5533\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3592 - accuracy: 0.5528 - val_loss: 1.3549 - val_accuracy: 0.5567\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3479 - accuracy: 0.5587 - val_loss: 1.3383 - val_accuracy: 0.5606\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3357 - accuracy: 0.5629 - val_loss: 1.3341 - val_accuracy: 0.5627\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3249 - accuracy: 0.5676 - val_loss: 1.3197 - val_accuracy: 0.5686\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3137 - accuracy: 0.5705 - val_loss: 1.3012 - val_accuracy: 0.5787\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3031 - accuracy: 0.5766 - val_loss: 1.2941 - val_accuracy: 0.5791\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2924 - accuracy: 0.5805 - val_loss: 1.2855 - val_accuracy: 0.5812\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2818 - accuracy: 0.5834 - val_loss: 1.2783 - val_accuracy: 0.5873\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2720 - accuracy: 0.5881 - val_loss: 1.2631 - val_accuracy: 0.5932\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2629 - accuracy: 0.5926 - val_loss: 1.2654 - val_accuracy: 0.5893\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2523 - accuracy: 0.5962 - val_loss: 1.2500 - val_accuracy: 0.5989\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2428 - accuracy: 0.6000 - val_loss: 1.2344 - val_accuracy: 0.6063\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2333 - accuracy: 0.6039 - val_loss: 1.2243 - val_accuracy: 0.6079\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2250 - accuracy: 0.6086 - val_loss: 1.2203 - val_accuracy: 0.6086\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2169 - accuracy: 0.6103 - val_loss: 1.2061 - val_accuracy: 0.6163\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2068 - accuracy: 0.6148 - val_loss: 1.2030 - val_accuracy: 0.6143\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1988 - accuracy: 0.6182 - val_loss: 1.1927 - val_accuracy: 0.6213\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1915 - accuracy: 0.6193 - val_loss: 1.1847 - val_accuracy: 0.6237\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1827 - accuracy: 0.6238 - val_loss: 1.1840 - val_accuracy: 0.6223\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1751 - accuracy: 0.6260 - val_loss: 1.1683 - val_accuracy: 0.6289\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 3s 3ms/step - loss: 1.1671 - accuracy: 0.6311 - val_loss: 1.1556 - val_accuracy: 0.6367\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 3s 3ms/step - loss: 1.1588 - accuracy: 0.6327 - val_loss: 1.1550 - val_accuracy: 0.6340\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 3s 3ms/step - loss: 1.1511 - accuracy: 0.6382 - val_loss: 1.1437 - val_accuracy: 0.6412\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1434 - accuracy: 0.6370 - val_loss: 1.1569 - val_accuracy: 0.6313\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1362 - accuracy: 0.6418 - val_loss: 1.1263 - val_accuracy: 0.6471\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1294 - accuracy: 0.6449 - val_loss: 1.1288 - val_accuracy: 0.6466\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1216 - accuracy: 0.6484 - val_loss: 1.1328 - val_accuracy: 0.6413\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 4s 5ms/step - loss: 1.1144 - accuracy: 0.6497 - val_loss: 1.1282 - val_accuracy: 0.6453\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1061 - accuracy: 0.6523 - val_loss: 1.1001 - val_accuracy: 0.6569\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1002 - accuracy: 0.6557 - val_loss: 1.0963 - val_accuracy: 0.6592\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.0924 - accuracy: 0.6594 - val_loss: 1.0882 - val_accuracy: 0.6611\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.0861 - accuracy: 0.6588 - val_loss: 1.0776 - val_accuracy: 0.6655\n"
     ]
    }
   ],
   "source": [
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train, batch_size = 50, epochs = 100, validation_data=(X_val, y_val), verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gFRGV7ztt1vS",
    "outputId": "cc418316-2655-4681-f8cc-464408da1d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 1ms/step - loss: 1.0896 - accuracy: 0.6661\n"
     ]
    }
   ],
   "source": [
    "Results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oD3JXTdTu7Gn",
    "outputId": "004cd96e-f40d-4c30-ebdb-c7ee221316e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.6661111116409302\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', Results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtWU_Z4okXbQ"
   },
   "source": [
    "2. Model adding Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skeUfjPQvKLJ"
   },
   "outputs": [],
   "source": [
    "#Adding Batch Normalization\n",
    "def mlp_model1():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(50, input_shape = (1024, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tHcWiFcHwggI",
    "outputId": "8b46b2fa-3947-42a8-a357-8f5b826de460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 2.4178 - accuracy: 0.1242 - val_loss: 2.3132 - val_accuracy: 0.1564\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.2035 - accuracy: 0.2027 - val_loss: 2.1127 - val_accuracy: 0.2487\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 2.0539 - accuracy: 0.2691 - val_loss: 1.9704 - val_accuracy: 0.3112\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.9352 - accuracy: 0.3274 - val_loss: 1.8431 - val_accuracy: 0.3738\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.8276 - accuracy: 0.3802 - val_loss: 1.7411 - val_accuracy: 0.4230\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.7352 - accuracy: 0.4280 - val_loss: 1.6405 - val_accuracy: 0.4665\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.6450 - accuracy: 0.4660 - val_loss: 1.5565 - val_accuracy: 0.5037\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.5725 - accuracy: 0.4935 - val_loss: 1.4673 - val_accuracy: 0.5403\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.5034 - accuracy: 0.5213 - val_loss: 1.4285 - val_accuracy: 0.5590\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.4449 - accuracy: 0.5452 - val_loss: 1.3793 - val_accuracy: 0.5658\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.3948 - accuracy: 0.5627 - val_loss: 1.3259 - val_accuracy: 0.5911\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.3532 - accuracy: 0.5754 - val_loss: 1.2696 - val_accuracy: 0.6098\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.3179 - accuracy: 0.5852 - val_loss: 1.2332 - val_accuracy: 0.6218\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.2844 - accuracy: 0.5969 - val_loss: 1.2195 - val_accuracy: 0.6194\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.2526 - accuracy: 0.6089 - val_loss: 1.2073 - val_accuracy: 0.6271\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.2235 - accuracy: 0.6188 - val_loss: 1.1430 - val_accuracy: 0.6503\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1960 - accuracy: 0.6261 - val_loss: 1.1180 - val_accuracy: 0.6608\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.1806 - accuracy: 0.6313 - val_loss: 1.1077 - val_accuracy: 0.6592\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1577 - accuracy: 0.6380 - val_loss: 1.0872 - val_accuracy: 0.6678\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.1380 - accuracy: 0.6455 - val_loss: 1.0658 - val_accuracy: 0.6714\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.1230 - accuracy: 0.6493 - val_loss: 1.0513 - val_accuracy: 0.6759\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.1052 - accuracy: 0.6531 - val_loss: 1.0582 - val_accuracy: 0.6708\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.0908 - accuracy: 0.6560 - val_loss: 1.0685 - val_accuracy: 0.6648\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.0709 - accuracy: 0.6636 - val_loss: 1.0270 - val_accuracy: 0.6775\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.0610 - accuracy: 0.6676 - val_loss: 0.9788 - val_accuracy: 0.6986\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.0464 - accuracy: 0.6718 - val_loss: 0.9726 - val_accuracy: 0.6992\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.0311 - accuracy: 0.6778 - val_loss: 0.9856 - val_accuracy: 0.6922\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.0237 - accuracy: 0.6782 - val_loss: 0.9827 - val_accuracy: 0.6941\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 1.0108 - accuracy: 0.6835 - val_loss: 0.9958 - val_accuracy: 0.6838\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 1.0003 - accuracy: 0.6890 - val_loss: 0.9246 - val_accuracy: 0.7155\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.9843 - accuracy: 0.6910 - val_loss: 0.9190 - val_accuracy: 0.7131\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.9799 - accuracy: 0.6934 - val_loss: 0.9519 - val_accuracy: 0.6983\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.9669 - accuracy: 0.6963 - val_loss: 0.8894 - val_accuracy: 0.7248\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.9531 - accuracy: 0.7000 - val_loss: 0.9047 - val_accuracy: 0.7189\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.9396 - accuracy: 0.7055 - val_loss: 0.8901 - val_accuracy: 0.7247\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.9332 - accuracy: 0.7093 - val_loss: 0.8895 - val_accuracy: 0.7218\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.9212 - accuracy: 0.7121 - val_loss: 0.8849 - val_accuracy: 0.7243\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.9194 - accuracy: 0.7121 - val_loss: 0.9036 - val_accuracy: 0.7171\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.9109 - accuracy: 0.7144 - val_loss: 0.8616 - val_accuracy: 0.7309\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.9002 - accuracy: 0.7188 - val_loss: 0.8359 - val_accuracy: 0.7425\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.8886 - accuracy: 0.7231 - val_loss: 0.8452 - val_accuracy: 0.7364\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.8860 - accuracy: 0.7225 - val_loss: 0.8452 - val_accuracy: 0.7351\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.8717 - accuracy: 0.7267 - val_loss: 0.8700 - val_accuracy: 0.7250\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.8706 - accuracy: 0.7291 - val_loss: 0.8396 - val_accuracy: 0.7360\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.8642 - accuracy: 0.7280 - val_loss: 0.8306 - val_accuracy: 0.7393\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 4s 5ms/step - loss: 0.8554 - accuracy: 0.7345 - val_loss: 0.8418 - val_accuracy: 0.7394\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.8518 - accuracy: 0.7337 - val_loss: 0.8456 - val_accuracy: 0.7387\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.8458 - accuracy: 0.7360 - val_loss: 0.8025 - val_accuracy: 0.7497\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.8389 - accuracy: 0.7392 - val_loss: 0.8176 - val_accuracy: 0.7488\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.8269 - accuracy: 0.7409 - val_loss: 0.7861 - val_accuracy: 0.7559\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.8273 - accuracy: 0.7425 - val_loss: 0.8395 - val_accuracy: 0.7350\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.8229 - accuracy: 0.7411 - val_loss: 0.8332 - val_accuracy: 0.7391\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.8183 - accuracy: 0.7424 - val_loss: 0.8048 - val_accuracy: 0.7497\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.8128 - accuracy: 0.7479 - val_loss: 0.8207 - val_accuracy: 0.7436\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.8075 - accuracy: 0.7477 - val_loss: 0.7936 - val_accuracy: 0.7514\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.8026 - accuracy: 0.7504 - val_loss: 0.8176 - val_accuracy: 0.7468\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7944 - accuracy: 0.7531 - val_loss: 0.8073 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7929 - accuracy: 0.7522 - val_loss: 0.7818 - val_accuracy: 0.7578\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7843 - accuracy: 0.7543 - val_loss: 0.7486 - val_accuracy: 0.7717\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7847 - accuracy: 0.7565 - val_loss: 0.7618 - val_accuracy: 0.7649\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7780 - accuracy: 0.7565 - val_loss: 0.8387 - val_accuracy: 0.7361\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7755 - accuracy: 0.7560 - val_loss: 0.7939 - val_accuracy: 0.7508\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7686 - accuracy: 0.7584 - val_loss: 0.7353 - val_accuracy: 0.7743\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7670 - accuracy: 0.7616 - val_loss: 0.7194 - val_accuracy: 0.7768\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7639 - accuracy: 0.7625 - val_loss: 0.8314 - val_accuracy: 0.7406\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7580 - accuracy: 0.7617 - val_loss: 0.7373 - val_accuracy: 0.7717\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7581 - accuracy: 0.7629 - val_loss: 0.7282 - val_accuracy: 0.7761\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7508 - accuracy: 0.7662 - val_loss: 0.7763 - val_accuracy: 0.7602\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7455 - accuracy: 0.7667 - val_loss: 0.7117 - val_accuracy: 0.7788\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 4s 5ms/step - loss: 0.7484 - accuracy: 0.7638 - val_loss: 0.7087 - val_accuracy: 0.7835\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 5s 6ms/step - loss: 0.7420 - accuracy: 0.7682 - val_loss: 0.7642 - val_accuracy: 0.7642\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7381 - accuracy: 0.7700 - val_loss: 0.7402 - val_accuracy: 0.7696\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7345 - accuracy: 0.7706 - val_loss: 0.7281 - val_accuracy: 0.7724\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7267 - accuracy: 0.7710 - val_loss: 0.7542 - val_accuracy: 0.7668\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7255 - accuracy: 0.7731 - val_loss: 0.6912 - val_accuracy: 0.7866\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7214 - accuracy: 0.7746 - val_loss: 0.7288 - val_accuracy: 0.7750\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 4s 5ms/step - loss: 0.7155 - accuracy: 0.7770 - val_loss: 0.7086 - val_accuracy: 0.7823\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7126 - accuracy: 0.7774 - val_loss: 0.7513 - val_accuracy: 0.7699\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7112 - accuracy: 0.7768 - val_loss: 0.6569 - val_accuracy: 0.7978\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7133 - accuracy: 0.7784 - val_loss: 0.6846 - val_accuracy: 0.7900\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.7084 - accuracy: 0.7809 - val_loss: 0.7269 - val_accuracy: 0.7749\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7036 - accuracy: 0.7822 - val_loss: 0.6743 - val_accuracy: 0.7883\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7061 - accuracy: 0.7803 - val_loss: 0.6710 - val_accuracy: 0.7923\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.7009 - accuracy: 0.7817 - val_loss: 0.6396 - val_accuracy: 0.8030\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.6932 - accuracy: 0.7843 - val_loss: 0.6551 - val_accuracy: 0.7972\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6914 - accuracy: 0.7848 - val_loss: 0.7645 - val_accuracy: 0.7603\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6937 - accuracy: 0.7853 - val_loss: 0.6754 - val_accuracy: 0.7935\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.6923 - accuracy: 0.7847 - val_loss: 0.7084 - val_accuracy: 0.7782\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6886 - accuracy: 0.7849 - val_loss: 0.6599 - val_accuracy: 0.7957\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6864 - accuracy: 0.7856 - val_loss: 0.7155 - val_accuracy: 0.7753\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6807 - accuracy: 0.7900 - val_loss: 0.6585 - val_accuracy: 0.7971\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.6798 - accuracy: 0.7878 - val_loss: 0.7136 - val_accuracy: 0.7776\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6772 - accuracy: 0.7888 - val_loss: 0.6515 - val_accuracy: 0.7972\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6779 - accuracy: 0.7866 - val_loss: 0.6767 - val_accuracy: 0.7897\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.6705 - accuracy: 0.7920 - val_loss: 0.6597 - val_accuracy: 0.7951\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6700 - accuracy: 0.7899 - val_loss: 0.6373 - val_accuracy: 0.8022\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.6694 - accuracy: 0.7908 - val_loss: 0.6330 - val_accuracy: 0.8055\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6679 - accuracy: 0.7935 - val_loss: 0.6786 - val_accuracy: 0.7911\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 3s 4ms/step - loss: 0.6647 - accuracy: 0.7921 - val_loss: 0.6253 - val_accuracy: 0.8061\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 4s 4ms/step - loss: 0.6606 - accuracy: 0.7938 - val_loss: 0.7211 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "model1 = mlp_model1()\n",
    "history1 = model1.fit(X_train, y_train, batch_size = 50, validation_data=(X_val, y_val), epochs = 100, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aRw9rQbSylqa",
    "outputId": "dd2d5546-cce0-4947-9930-4407bc690fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 1ms/step - loss: 0.8064 - accuracy: 0.7476\n"
     ]
    }
   ],
   "source": [
    "Results1 = model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p8vrWzstk16g"
   },
   "source": [
    "Test accuracy increases from 66% to 74.7% on adding Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qLnyzmki2rse",
    "outputId": "c4c9c17a-2ed6-43de-eb2d-96e2002c0d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7475555539131165\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', Results1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqxyV8CiloRy"
   },
   "source": [
    "#Changing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nufnAU7dltqF"
   },
   "source": [
    "#1. Adding more hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvsFGzOX7Kuv"
   },
   "outputs": [],
   "source": [
    "#Tweaking hyperparameters to check if a better accuracy is possible\n",
    "#Adding 2 more layers of 50 neurons\n",
    "def mlp_model2():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(50, input_shape = (1024, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0s6wljpu8Dw9",
    "outputId": "b9779e19-d2eb-4200-f4a5-70e6bbd01af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.5648 - accuracy: 0.1228 - val_loss: 2.4062 - val_accuracy: 0.1477\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.3421 - accuracy: 0.1695 - val_loss: 2.2943 - val_accuracy: 0.1905\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.1961 - accuracy: 0.2126 - val_loss: 2.1688 - val_accuracy: 0.2334\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.0917 - accuracy: 0.2514 - val_loss: 2.0446 - val_accuracy: 0.2725\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.0008 - accuracy: 0.2901 - val_loss: 1.9598 - val_accuracy: 0.3110\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9309 - accuracy: 0.3221 - val_loss: 1.8916 - val_accuracy: 0.3427\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8656 - accuracy: 0.3513 - val_loss: 1.8321 - val_accuracy: 0.3711\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8101 - accuracy: 0.3784 - val_loss: 1.7913 - val_accuracy: 0.3877\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7618 - accuracy: 0.4034 - val_loss: 1.7301 - val_accuracy: 0.4196\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7166 - accuracy: 0.4250 - val_loss: 1.6836 - val_accuracy: 0.4406\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6687 - accuracy: 0.4497 - val_loss: 1.6296 - val_accuracy: 0.4648\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6301 - accuracy: 0.4670 - val_loss: 1.6006 - val_accuracy: 0.4837\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5942 - accuracy: 0.4820 - val_loss: 1.5699 - val_accuracy: 0.4929\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5568 - accuracy: 0.4986 - val_loss: 1.4880 - val_accuracy: 0.5289\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5214 - accuracy: 0.5133 - val_loss: 1.4917 - val_accuracy: 0.5211\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.4881 - accuracy: 0.5270 - val_loss: 1.4437 - val_accuracy: 0.5484\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.4628 - accuracy: 0.5347 - val_loss: 1.4130 - val_accuracy: 0.5591\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.4346 - accuracy: 0.5482 - val_loss: 1.3862 - val_accuracy: 0.5693\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.4131 - accuracy: 0.5580 - val_loss: 1.3743 - val_accuracy: 0.5745\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.3833 - accuracy: 0.5677 - val_loss: 1.3477 - val_accuracy: 0.5804\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.3631 - accuracy: 0.5753 - val_loss: 1.3127 - val_accuracy: 0.5970\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.3384 - accuracy: 0.5860 - val_loss: 1.2979 - val_accuracy: 0.5979\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.3185 - accuracy: 0.5898 - val_loss: 1.2611 - val_accuracy: 0.6122\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.3030 - accuracy: 0.5952 - val_loss: 1.2572 - val_accuracy: 0.6153\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2841 - accuracy: 0.6024 - val_loss: 1.2329 - val_accuracy: 0.6194\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2655 - accuracy: 0.6073 - val_loss: 1.2142 - val_accuracy: 0.6259\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2502 - accuracy: 0.6107 - val_loss: 1.2240 - val_accuracy: 0.6207\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2315 - accuracy: 0.6195 - val_loss: 1.1909 - val_accuracy: 0.6335\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2181 - accuracy: 0.6228 - val_loss: 1.1809 - val_accuracy: 0.6346\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2004 - accuracy: 0.6306 - val_loss: 1.1537 - val_accuracy: 0.6476\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1903 - accuracy: 0.6312 - val_loss: 1.1430 - val_accuracy: 0.6519\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.1745 - accuracy: 0.6398 - val_loss: 1.1143 - val_accuracy: 0.6606\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1637 - accuracy: 0.6418 - val_loss: 1.1047 - val_accuracy: 0.6631\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1473 - accuracy: 0.6458 - val_loss: 1.1079 - val_accuracy: 0.6598\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1409 - accuracy: 0.6498 - val_loss: 1.0856 - val_accuracy: 0.6695\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1276 - accuracy: 0.6529 - val_loss: 1.0804 - val_accuracy: 0.6702\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1150 - accuracy: 0.6573 - val_loss: 1.0762 - val_accuracy: 0.6725\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1052 - accuracy: 0.6608 - val_loss: 1.0880 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0957 - accuracy: 0.6650 - val_loss: 1.0586 - val_accuracy: 0.6754\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0834 - accuracy: 0.6695 - val_loss: 1.0326 - val_accuracy: 0.6848\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0771 - accuracy: 0.6703 - val_loss: 1.0390 - val_accuracy: 0.6827\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0687 - accuracy: 0.6730 - val_loss: 1.0056 - val_accuracy: 0.6943\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0568 - accuracy: 0.6764 - val_loss: 1.0228 - val_accuracy: 0.6847\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0478 - accuracy: 0.6805 - val_loss: 1.0029 - val_accuracy: 0.6947\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0412 - accuracy: 0.6805 - val_loss: 1.0271 - val_accuracy: 0.6872\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0315 - accuracy: 0.6840 - val_loss: 0.9685 - val_accuracy: 0.7059\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0244 - accuracy: 0.6849 - val_loss: 1.0242 - val_accuracy: 0.6821\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0151 - accuracy: 0.6901 - val_loss: 0.9827 - val_accuracy: 0.6992\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0066 - accuracy: 0.6918 - val_loss: 0.9716 - val_accuracy: 0.7045\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9993 - accuracy: 0.6951 - val_loss: 0.9676 - val_accuracy: 0.7025\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9943 - accuracy: 0.6962 - val_loss: 0.9427 - val_accuracy: 0.7120\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9867 - accuracy: 0.6984 - val_loss: 0.9561 - val_accuracy: 0.7067\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9820 - accuracy: 0.6977 - val_loss: 0.9392 - val_accuracy: 0.7115\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9717 - accuracy: 0.7038 - val_loss: 0.9364 - val_accuracy: 0.7138\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9713 - accuracy: 0.7010 - val_loss: 0.9262 - val_accuracy: 0.7165\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9587 - accuracy: 0.7073 - val_loss: 0.9074 - val_accuracy: 0.7229\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9517 - accuracy: 0.7084 - val_loss: 0.9201 - val_accuracy: 0.7194\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9500 - accuracy: 0.7085 - val_loss: 0.9138 - val_accuracy: 0.7215\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9461 - accuracy: 0.7108 - val_loss: 0.8999 - val_accuracy: 0.7262\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9373 - accuracy: 0.7145 - val_loss: 0.9008 - val_accuracy: 0.7239\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9301 - accuracy: 0.7139 - val_loss: 0.8958 - val_accuracy: 0.7275\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9284 - accuracy: 0.7154 - val_loss: 0.9138 - val_accuracy: 0.7213\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9267 - accuracy: 0.7163 - val_loss: 0.8594 - val_accuracy: 0.7376\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9127 - accuracy: 0.7215 - val_loss: 0.8809 - val_accuracy: 0.7304\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9101 - accuracy: 0.7221 - val_loss: 0.8868 - val_accuracy: 0.7262\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9037 - accuracy: 0.7236 - val_loss: 0.8567 - val_accuracy: 0.7411\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8986 - accuracy: 0.7244 - val_loss: 0.9060 - val_accuracy: 0.7204\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8994 - accuracy: 0.7237 - val_loss: 0.8477 - val_accuracy: 0.7417\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8924 - accuracy: 0.7255 - val_loss: 0.8779 - val_accuracy: 0.7278\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.8877 - accuracy: 0.7280 - val_loss: 0.8686 - val_accuracy: 0.7327\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8815 - accuracy: 0.7292 - val_loss: 0.8484 - val_accuracy: 0.7408\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8729 - accuracy: 0.7321 - val_loss: 0.8399 - val_accuracy: 0.7423\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8736 - accuracy: 0.7307 - val_loss: 0.8351 - val_accuracy: 0.7459\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8686 - accuracy: 0.7338 - val_loss: 0.8511 - val_accuracy: 0.7365\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8660 - accuracy: 0.7356 - val_loss: 0.8597 - val_accuracy: 0.7349\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8578 - accuracy: 0.7386 - val_loss: 0.8159 - val_accuracy: 0.7511\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8581 - accuracy: 0.7361 - val_loss: 0.8146 - val_accuracy: 0.7533\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8530 - accuracy: 0.7391 - val_loss: 0.8408 - val_accuracy: 0.7416\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8491 - accuracy: 0.7413 - val_loss: 0.7897 - val_accuracy: 0.7603\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8467 - accuracy: 0.7411 - val_loss: 0.8643 - val_accuracy: 0.7305\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8411 - accuracy: 0.7451 - val_loss: 0.8189 - val_accuracy: 0.7480\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8435 - accuracy: 0.7417 - val_loss: 0.8210 - val_accuracy: 0.7491\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8269 - accuracy: 0.7480 - val_loss: 0.8109 - val_accuracy: 0.7502\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8356 - accuracy: 0.7432 - val_loss: 0.8315 - val_accuracy: 0.7423\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8224 - accuracy: 0.7492 - val_loss: 0.7823 - val_accuracy: 0.7611\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8230 - accuracy: 0.7492 - val_loss: 0.8074 - val_accuracy: 0.7491\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8221 - accuracy: 0.7473 - val_loss: 0.7819 - val_accuracy: 0.7605\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8158 - accuracy: 0.7480 - val_loss: 0.7641 - val_accuracy: 0.7676\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8123 - accuracy: 0.7504 - val_loss: 0.7857 - val_accuracy: 0.7568\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8045 - accuracy: 0.7535 - val_loss: 0.7609 - val_accuracy: 0.7680\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8064 - accuracy: 0.7532 - val_loss: 0.8043 - val_accuracy: 0.7543\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7999 - accuracy: 0.7553 - val_loss: 0.7639 - val_accuracy: 0.7686\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7994 - accuracy: 0.7558 - val_loss: 0.7527 - val_accuracy: 0.7695\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7969 - accuracy: 0.7560 - val_loss: 0.7623 - val_accuracy: 0.7668\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7945 - accuracy: 0.7577 - val_loss: 0.7750 - val_accuracy: 0.7639\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7879 - accuracy: 0.7593 - val_loss: 0.7447 - val_accuracy: 0.7729\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7840 - accuracy: 0.7591 - val_loss: 0.7512 - val_accuracy: 0.7700\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7865 - accuracy: 0.7579 - val_loss: 0.7393 - val_accuracy: 0.7750\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7826 - accuracy: 0.7605 - val_loss: 0.7512 - val_accuracy: 0.7698\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.7828 - accuracy: 0.7589 - val_loss: 0.7638 - val_accuracy: 0.7653\n"
     ]
    }
   ],
   "source": [
    "model2 = mlp_model2()\n",
    "history2 = model2.fit(X_train, y_train, batch_size=100, validation_data=(X_val, y_val), epochs = 100, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F2y7xRqY_LK_",
    "outputId": "febc8a91-a60b-4446-d90e-f07b76ba61c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 0.8405 - accuracy: 0.7403\n"
     ]
    }
   ],
   "source": [
    "Results2 = model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "995kN4GmmMGF"
   },
   "source": [
    "The accuracy drops slightly from 74.7% to 74.0%, so we can go with 5 layers itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRRHfEJ2noUo"
   },
   "source": [
    "#2. Adding more neurons in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Zb_-jf0_V0c"
   },
   "outputs": [],
   "source": [
    "#Increasing number of neurons per layer to 70\n",
    "def mlp_model3():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(70, input_shape = (1024, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(70))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(70))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(70))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "reDweUjO_p-9",
    "outputId": "21fe7933-42f2-46a3-9030-154636674d2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.5754 - accuracy: 0.1238 - val_loss: 2.4274 - val_accuracy: 0.1459\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.3284 - accuracy: 0.1867 - val_loss: 2.2570 - val_accuracy: 0.2113\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.1498 - accuracy: 0.2437 - val_loss: 2.0773 - val_accuracy: 0.2715\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.0204 - accuracy: 0.2935 - val_loss: 1.9553 - val_accuracy: 0.3213\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.9194 - accuracy: 0.3396 - val_loss: 1.8603 - val_accuracy: 0.3729\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8389 - accuracy: 0.3774 - val_loss: 1.7818 - val_accuracy: 0.4058\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7700 - accuracy: 0.4106 - val_loss: 1.7260 - val_accuracy: 0.4344\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7152 - accuracy: 0.4379 - val_loss: 1.6518 - val_accuracy: 0.4720\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6588 - accuracy: 0.4667 - val_loss: 1.6176 - val_accuracy: 0.4897\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6080 - accuracy: 0.4900 - val_loss: 1.5515 - val_accuracy: 0.5195\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5652 - accuracy: 0.5081 - val_loss: 1.5100 - val_accuracy: 0.5328\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5268 - accuracy: 0.5266 - val_loss: 1.4686 - val_accuracy: 0.5539\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.4841 - accuracy: 0.5431 - val_loss: 1.4469 - val_accuracy: 0.5590\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.4504 - accuracy: 0.5564 - val_loss: 1.3934 - val_accuracy: 0.5782\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.4183 - accuracy: 0.5684 - val_loss: 1.3715 - val_accuracy: 0.5924\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.3874 - accuracy: 0.5785 - val_loss: 1.3438 - val_accuracy: 0.6009\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.3592 - accuracy: 0.5897 - val_loss: 1.3080 - val_accuracy: 0.6140\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.3364 - accuracy: 0.5980 - val_loss: 1.2917 - val_accuracy: 0.6129\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.3101 - accuracy: 0.6066 - val_loss: 1.2526 - val_accuracy: 0.6305\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2843 - accuracy: 0.6145 - val_loss: 1.2402 - val_accuracy: 0.6372\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2663 - accuracy: 0.6207 - val_loss: 1.2307 - val_accuracy: 0.6378\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.2423 - accuracy: 0.6282 - val_loss: 1.1841 - val_accuracy: 0.6514\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2297 - accuracy: 0.6318 - val_loss: 1.1784 - val_accuracy: 0.6565\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.2041 - accuracy: 0.6417 - val_loss: 1.1539 - val_accuracy: 0.6633\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1867 - accuracy: 0.6482 - val_loss: 1.1447 - val_accuracy: 0.6649\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1717 - accuracy: 0.6495 - val_loss: 1.1178 - val_accuracy: 0.6749\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1571 - accuracy: 0.6548 - val_loss: 1.1102 - val_accuracy: 0.6776\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1428 - accuracy: 0.6593 - val_loss: 1.0939 - val_accuracy: 0.6772\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1279 - accuracy: 0.6641 - val_loss: 1.0665 - val_accuracy: 0.6877\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1135 - accuracy: 0.6669 - val_loss: 1.0818 - val_accuracy: 0.6806\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.1013 - accuracy: 0.6737 - val_loss: 1.0497 - val_accuracy: 0.6943\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0864 - accuracy: 0.6755 - val_loss: 1.0435 - val_accuracy: 0.6961\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0792 - accuracy: 0.6786 - val_loss: 1.0318 - val_accuracy: 0.6957\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0662 - accuracy: 0.6810 - val_loss: 1.0228 - val_accuracy: 0.6994\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0562 - accuracy: 0.6855 - val_loss: 1.0245 - val_accuracy: 0.6987\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0477 - accuracy: 0.6871 - val_loss: 1.0130 - val_accuracy: 0.7015\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0341 - accuracy: 0.6897 - val_loss: 1.0134 - val_accuracy: 0.6989\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0273 - accuracy: 0.6936 - val_loss: 0.9793 - val_accuracy: 0.7110\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0183 - accuracy: 0.6950 - val_loss: 0.9805 - val_accuracy: 0.7140\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0054 - accuracy: 0.6994 - val_loss: 0.9716 - val_accuracy: 0.7086\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.0034 - accuracy: 0.6976 - val_loss: 0.9497 - val_accuracy: 0.7188\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9927 - accuracy: 0.7017 - val_loss: 0.9645 - val_accuracy: 0.7130\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9843 - accuracy: 0.7059 - val_loss: 0.9443 - val_accuracy: 0.7189\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9744 - accuracy: 0.7077 - val_loss: 0.9288 - val_accuracy: 0.7265\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9682 - accuracy: 0.7093 - val_loss: 0.9444 - val_accuracy: 0.7164\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9608 - accuracy: 0.7124 - val_loss: 0.9182 - val_accuracy: 0.7272\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9550 - accuracy: 0.7141 - val_loss: 0.9129 - val_accuracy: 0.7301\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9439 - accuracy: 0.7178 - val_loss: 0.9030 - val_accuracy: 0.7329\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9417 - accuracy: 0.7168 - val_loss: 0.9064 - val_accuracy: 0.7287\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9335 - accuracy: 0.7193 - val_loss: 0.8919 - val_accuracy: 0.7350\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9253 - accuracy: 0.7211 - val_loss: 0.8798 - val_accuracy: 0.7404\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9202 - accuracy: 0.7233 - val_loss: 0.9038 - val_accuracy: 0.7268\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9127 - accuracy: 0.7249 - val_loss: 0.8829 - val_accuracy: 0.7383\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9106 - accuracy: 0.7274 - val_loss: 0.8693 - val_accuracy: 0.7453\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9007 - accuracy: 0.7280 - val_loss: 0.8634 - val_accuracy: 0.7411\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8966 - accuracy: 0.7282 - val_loss: 0.8567 - val_accuracy: 0.7442\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8905 - accuracy: 0.7300 - val_loss: 0.8618 - val_accuracy: 0.7410\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8859 - accuracy: 0.7320 - val_loss: 0.8603 - val_accuracy: 0.7428\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8816 - accuracy: 0.7356 - val_loss: 0.8428 - val_accuracy: 0.7515\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8750 - accuracy: 0.7349 - val_loss: 0.8602 - val_accuracy: 0.7421\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8701 - accuracy: 0.7382 - val_loss: 0.8425 - val_accuracy: 0.7469\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8706 - accuracy: 0.7357 - val_loss: 0.8351 - val_accuracy: 0.7494\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8606 - accuracy: 0.7407 - val_loss: 0.8266 - val_accuracy: 0.7534\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8546 - accuracy: 0.7426 - val_loss: 0.8125 - val_accuracy: 0.7542\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8504 - accuracy: 0.7439 - val_loss: 0.8233 - val_accuracy: 0.7527\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8416 - accuracy: 0.7448 - val_loss: 0.8157 - val_accuracy: 0.7568\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8415 - accuracy: 0.7455 - val_loss: 0.8074 - val_accuracy: 0.7588\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8347 - accuracy: 0.7482 - val_loss: 0.8054 - val_accuracy: 0.7608\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8323 - accuracy: 0.7480 - val_loss: 0.7978 - val_accuracy: 0.7632\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8286 - accuracy: 0.7489 - val_loss: 0.7821 - val_accuracy: 0.7674\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8256 - accuracy: 0.7495 - val_loss: 0.7793 - val_accuracy: 0.7662\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8208 - accuracy: 0.7516 - val_loss: 0.7991 - val_accuracy: 0.7600\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8137 - accuracy: 0.7540 - val_loss: 0.7864 - val_accuracy: 0.7654\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.8072 - accuracy: 0.7579 - val_loss: 0.7760 - val_accuracy: 0.7666\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8047 - accuracy: 0.7556 - val_loss: 0.7801 - val_accuracy: 0.7657\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.8044 - accuracy: 0.7569 - val_loss: 0.7851 - val_accuracy: 0.7638\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7978 - accuracy: 0.7562 - val_loss: 0.7953 - val_accuracy: 0.7575\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7950 - accuracy: 0.7577 - val_loss: 0.7875 - val_accuracy: 0.7606\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7942 - accuracy: 0.7572 - val_loss: 0.7661 - val_accuracy: 0.7712\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7909 - accuracy: 0.7599 - val_loss: 0.7580 - val_accuracy: 0.7722\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7849 - accuracy: 0.7609 - val_loss: 0.7689 - val_accuracy: 0.7691\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7843 - accuracy: 0.7603 - val_loss: 0.7482 - val_accuracy: 0.7747\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7769 - accuracy: 0.7641 - val_loss: 0.7428 - val_accuracy: 0.7787\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7704 - accuracy: 0.7658 - val_loss: 0.7317 - val_accuracy: 0.7818\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7711 - accuracy: 0.7662 - val_loss: 0.7689 - val_accuracy: 0.7656\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7664 - accuracy: 0.7664 - val_loss: 0.7407 - val_accuracy: 0.7775\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7651 - accuracy: 0.7673 - val_loss: 0.7205 - val_accuracy: 0.7850\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7587 - accuracy: 0.7716 - val_loss: 0.7335 - val_accuracy: 0.7789\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7567 - accuracy: 0.7720 - val_loss: 0.7233 - val_accuracy: 0.7834\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7567 - accuracy: 0.7710 - val_loss: 0.7330 - val_accuracy: 0.7777\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7497 - accuracy: 0.7704 - val_loss: 0.7321 - val_accuracy: 0.7769\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7447 - accuracy: 0.7735 - val_loss: 0.7179 - val_accuracy: 0.7851\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7443 - accuracy: 0.7728 - val_loss: 0.7602 - val_accuracy: 0.7682\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7380 - accuracy: 0.7752 - val_loss: 0.7168 - val_accuracy: 0.7835\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7378 - accuracy: 0.7763 - val_loss: 0.7172 - val_accuracy: 0.7829\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7316 - accuracy: 0.7773 - val_loss: 0.7206 - val_accuracy: 0.7834\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7305 - accuracy: 0.7780 - val_loss: 0.6974 - val_accuracy: 0.7915\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7292 - accuracy: 0.7772 - val_loss: 0.7099 - val_accuracy: 0.7853\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7208 - accuracy: 0.7820 - val_loss: 0.7198 - val_accuracy: 0.7812\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.7162 - accuracy: 0.7835 - val_loss: 0.7204 - val_accuracy: 0.7819\n"
     ]
    }
   ],
   "source": [
    "model3 = mlp_model3()\n",
    "history3 = model3.fit(X_train, y_train, batch_size=100, validation_data=(X_val, y_val), epochs = 100, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Df6qEhzBB0tO",
    "outputId": "2a1160dd-cf33-4a8a-ac8f-2dad33be141d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 0.8051 - accuracy: 0.7557\n"
     ]
    }
   ],
   "source": [
    "Results3 = model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlbkgko0nyQn"
   },
   "source": [
    "There is an icrease from 74.7% to 75.5%. \n",
    "Thus we can try to increase number of neurons futhur and check if it improves the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhLK_Jy9DfsM"
   },
   "outputs": [],
   "source": [
    "#Increasing number of neurons per layer to 100\n",
    "def mlp_model4():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(100, input_shape = (1024, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N-TphQm7D6uW",
    "outputId": "227adf63-6da3-45da-d489-49bdc4c871f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 2.5487 - accuracy: 0.1304 - val_loss: 2.3694 - val_accuracy: 0.1612\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 2.3115 - accuracy: 0.1920 - val_loss: 2.2271 - val_accuracy: 0.2213\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 2.1325 - accuracy: 0.2466 - val_loss: 2.0647 - val_accuracy: 0.2778\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.9872 - accuracy: 0.3061 - val_loss: 1.9163 - val_accuracy: 0.3387\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.8776 - accuracy: 0.3531 - val_loss: 1.8169 - val_accuracy: 0.3830\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.7907 - accuracy: 0.3962 - val_loss: 1.7338 - val_accuracy: 0.4219\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.7153 - accuracy: 0.4318 - val_loss: 1.6673 - val_accuracy: 0.4542\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.6533 - accuracy: 0.4627 - val_loss: 1.6053 - val_accuracy: 0.4872\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.5981 - accuracy: 0.4881 - val_loss: 1.5516 - val_accuracy: 0.5117\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.5487 - accuracy: 0.5123 - val_loss: 1.5159 - val_accuracy: 0.5307\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.5062 - accuracy: 0.5309 - val_loss: 1.4609 - val_accuracy: 0.5523\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.4670 - accuracy: 0.5469 - val_loss: 1.4251 - val_accuracy: 0.5683\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.4307 - accuracy: 0.5613 - val_loss: 1.3891 - val_accuracy: 0.5831\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.3994 - accuracy: 0.5735 - val_loss: 1.3515 - val_accuracy: 0.5961\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.3706 - accuracy: 0.5844 - val_loss: 1.3297 - val_accuracy: 0.6085\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.3388 - accuracy: 0.5979 - val_loss: 1.2896 - val_accuracy: 0.6223\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.3117 - accuracy: 0.6090 - val_loss: 1.2656 - val_accuracy: 0.6308\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.2882 - accuracy: 0.6141 - val_loss: 1.2387 - val_accuracy: 0.6401\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.2601 - accuracy: 0.6249 - val_loss: 1.2217 - val_accuracy: 0.6436\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.2411 - accuracy: 0.6326 - val_loss: 1.2034 - val_accuracy: 0.6492\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.2157 - accuracy: 0.6420 - val_loss: 1.1783 - val_accuracy: 0.6559\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.1959 - accuracy: 0.6462 - val_loss: 1.1494 - val_accuracy: 0.6664\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.1740 - accuracy: 0.6525 - val_loss: 1.1335 - val_accuracy: 0.6693\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.1574 - accuracy: 0.6566 - val_loss: 1.1129 - val_accuracy: 0.6780\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.1411 - accuracy: 0.6621 - val_loss: 1.0859 - val_accuracy: 0.6858\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.1229 - accuracy: 0.6689 - val_loss: 1.0774 - val_accuracy: 0.6883\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.1059 - accuracy: 0.6740 - val_loss: 1.0553 - val_accuracy: 0.6943\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0876 - accuracy: 0.6805 - val_loss: 1.0464 - val_accuracy: 0.6984\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0714 - accuracy: 0.6820 - val_loss: 1.0278 - val_accuracy: 0.6987\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0593 - accuracy: 0.6853 - val_loss: 1.0156 - val_accuracy: 0.7045\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0516 - accuracy: 0.6877 - val_loss: 1.0055 - val_accuracy: 0.7079\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0347 - accuracy: 0.6935 - val_loss: 0.9949 - val_accuracy: 0.7057\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0214 - accuracy: 0.6966 - val_loss: 0.9947 - val_accuracy: 0.7072\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0114 - accuracy: 0.7016 - val_loss: 0.9690 - val_accuracy: 0.7144\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9970 - accuracy: 0.7050 - val_loss: 0.9553 - val_accuracy: 0.7217\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9882 - accuracy: 0.7086 - val_loss: 0.9418 - val_accuracy: 0.7262\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9784 - accuracy: 0.7101 - val_loss: 0.9419 - val_accuracy: 0.7275\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9665 - accuracy: 0.7121 - val_loss: 0.9269 - val_accuracy: 0.7308\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9581 - accuracy: 0.7165 - val_loss: 0.9167 - val_accuracy: 0.7337\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9438 - accuracy: 0.7206 - val_loss: 0.9108 - val_accuracy: 0.7319\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9376 - accuracy: 0.7203 - val_loss: 0.9172 - val_accuracy: 0.7280\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9255 - accuracy: 0.7252 - val_loss: 0.8903 - val_accuracy: 0.7402\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9218 - accuracy: 0.7246 - val_loss: 0.8805 - val_accuracy: 0.7425\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9052 - accuracy: 0.7320 - val_loss: 0.8881 - val_accuracy: 0.7368\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9020 - accuracy: 0.7326 - val_loss: 0.8766 - val_accuracy: 0.7405\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8946 - accuracy: 0.7337 - val_loss: 0.8518 - val_accuracy: 0.7514\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8829 - accuracy: 0.7354 - val_loss: 0.8442 - val_accuracy: 0.7525\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8739 - accuracy: 0.7380 - val_loss: 0.8677 - val_accuracy: 0.7408\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8691 - accuracy: 0.7411 - val_loss: 0.8356 - val_accuracy: 0.7535\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8598 - accuracy: 0.7433 - val_loss: 0.8246 - val_accuracy: 0.7588\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8504 - accuracy: 0.7470 - val_loss: 0.8232 - val_accuracy: 0.7574\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8506 - accuracy: 0.7458 - val_loss: 0.8082 - val_accuracy: 0.7621\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8423 - accuracy: 0.7498 - val_loss: 0.8014 - val_accuracy: 0.7644\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8315 - accuracy: 0.7517 - val_loss: 0.8266 - val_accuracy: 0.7558\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8267 - accuracy: 0.7545 - val_loss: 0.8053 - val_accuracy: 0.7615\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8216 - accuracy: 0.7540 - val_loss: 0.7971 - val_accuracy: 0.7646\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8126 - accuracy: 0.7566 - val_loss: 0.7751 - val_accuracy: 0.7712\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8053 - accuracy: 0.7587 - val_loss: 0.7830 - val_accuracy: 0.7697\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8055 - accuracy: 0.7575 - val_loss: 0.7799 - val_accuracy: 0.7705\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7990 - accuracy: 0.7625 - val_loss: 0.7608 - val_accuracy: 0.7769\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7930 - accuracy: 0.7623 - val_loss: 0.7662 - val_accuracy: 0.7742\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7864 - accuracy: 0.7653 - val_loss: 0.7603 - val_accuracy: 0.7764\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7776 - accuracy: 0.7666 - val_loss: 0.7484 - val_accuracy: 0.7790\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7725 - accuracy: 0.7684 - val_loss: 0.7423 - val_accuracy: 0.7823\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7701 - accuracy: 0.7690 - val_loss: 0.7442 - val_accuracy: 0.7822\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7613 - accuracy: 0.7725 - val_loss: 0.7426 - val_accuracy: 0.7799\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7558 - accuracy: 0.7743 - val_loss: 0.7288 - val_accuracy: 0.7868\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7542 - accuracy: 0.7726 - val_loss: 0.7211 - val_accuracy: 0.7868\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7482 - accuracy: 0.7773 - val_loss: 0.7413 - val_accuracy: 0.7793\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7466 - accuracy: 0.7751 - val_loss: 0.7349 - val_accuracy: 0.7792\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7387 - accuracy: 0.7800 - val_loss: 0.7337 - val_accuracy: 0.7810\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7336 - accuracy: 0.7792 - val_loss: 0.7047 - val_accuracy: 0.7929\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7307 - accuracy: 0.7833 - val_loss: 0.7314 - val_accuracy: 0.7807\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7233 - accuracy: 0.7842 - val_loss: 0.7037 - val_accuracy: 0.7906\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7206 - accuracy: 0.7837 - val_loss: 0.6938 - val_accuracy: 0.7952\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7171 - accuracy: 0.7848 - val_loss: 0.7101 - val_accuracy: 0.7889\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7137 - accuracy: 0.7856 - val_loss: 0.7017 - val_accuracy: 0.7927\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.7084 - accuracy: 0.7866 - val_loss: 0.6863 - val_accuracy: 0.7976\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 5s 11ms/step - loss: 0.7014 - accuracy: 0.7901 - val_loss: 0.6838 - val_accuracy: 0.7964\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 5s 12ms/step - loss: 0.6989 - accuracy: 0.7898 - val_loss: 0.6758 - val_accuracy: 0.8005\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.6953 - accuracy: 0.7912 - val_loss: 0.6907 - val_accuracy: 0.7949\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 4s 8ms/step - loss: 0.6922 - accuracy: 0.7918 - val_loss: 0.6632 - val_accuracy: 0.8042\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6891 - accuracy: 0.7933 - val_loss: 0.6681 - val_accuracy: 0.8031\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6851 - accuracy: 0.7945 - val_loss: 0.6715 - val_accuracy: 0.7996\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6807 - accuracy: 0.7945 - val_loss: 0.6792 - val_accuracy: 0.7965\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6776 - accuracy: 0.7959 - val_loss: 0.6531 - val_accuracy: 0.8077\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6702 - accuracy: 0.7983 - val_loss: 0.6496 - val_accuracy: 0.8079\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.6693 - accuracy: 0.7985 - val_loss: 0.6858 - val_accuracy: 0.7936\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6617 - accuracy: 0.8014 - val_loss: 0.6434 - val_accuracy: 0.8097\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6617 - accuracy: 0.8016 - val_loss: 0.6539 - val_accuracy: 0.8069\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6598 - accuracy: 0.8026 - val_loss: 0.6378 - val_accuracy: 0.8130\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6535 - accuracy: 0.8019 - val_loss: 0.6454 - val_accuracy: 0.8067\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6552 - accuracy: 0.8034 - val_loss: 0.6319 - val_accuracy: 0.8130\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6470 - accuracy: 0.8060 - val_loss: 0.6349 - val_accuracy: 0.8135\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6445 - accuracy: 0.8047 - val_loss: 0.6348 - val_accuracy: 0.8109\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6405 - accuracy: 0.8083 - val_loss: 0.6226 - val_accuracy: 0.8160\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6364 - accuracy: 0.8097 - val_loss: 0.6306 - val_accuracy: 0.8128\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6380 - accuracy: 0.8085 - val_loss: 0.6748 - val_accuracy: 0.7956\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6358 - accuracy: 0.8099 - val_loss: 0.6326 - val_accuracy: 0.8112\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6307 - accuracy: 0.8094 - val_loss: 0.6099 - val_accuracy: 0.8189\n"
     ]
    }
   ],
   "source": [
    "model4 = mlp_model4()\n",
    "history4 = model4.fit(X_train, y_train, batch_size=100, validation_data=(X_val, y_val), epochs = 100, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T_CyquuPFzlM",
    "outputId": "3330a48c-3f03-4435-d1aa-dd6e0c9edd3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 0.7252 - accuracy: 0.7836\n"
     ]
    }
   ],
   "source": [
    "Results4 = model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1z2oqmgoR_I"
   },
   "source": [
    "Accuracy increases again from 75.5% to 78.36%. Let us try and increase number of neurons again to see if there is improvement in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBzBnkSFoiX_"
   },
   "outputs": [],
   "source": [
    "#Increasing number of neurons per layer to 200\n",
    "def mlp_model8():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(200, input_shape = (1024, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(200))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(200))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(200))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tbw8T4Jwow55",
    "outputId": "aafeee22-4b78-4f65-92d2-6d56aaebf88c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 2.5241 - accuracy: 0.1352 - val_loss: 2.3199 - val_accuracy: 0.1715\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 2.2111 - accuracy: 0.2162 - val_loss: 2.1171 - val_accuracy: 0.2589\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 2.0444 - accuracy: 0.2886 - val_loss: 1.9682 - val_accuracy: 0.3261\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 1.9127 - accuracy: 0.3499 - val_loss: 1.8340 - val_accuracy: 0.3855\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.7954 - accuracy: 0.4015 - val_loss: 1.7198 - val_accuracy: 0.4392\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 1.6977 - accuracy: 0.4453 - val_loss: 1.6262 - val_accuracy: 0.4787\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 6s 15ms/step - loss: 1.6153 - accuracy: 0.4818 - val_loss: 1.5580 - val_accuracy: 0.5135\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 1.5453 - accuracy: 0.5136 - val_loss: 1.4941 - val_accuracy: 0.5381\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.4876 - accuracy: 0.5380 - val_loss: 1.4349 - val_accuracy: 0.5644\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.4358 - accuracy: 0.5626 - val_loss: 1.3803 - val_accuracy: 0.5865\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.3974 - accuracy: 0.5772 - val_loss: 1.3408 - val_accuracy: 0.6030\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.3583 - accuracy: 0.5925 - val_loss: 1.3015 - val_accuracy: 0.6181\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 1.3156 - accuracy: 0.6090 - val_loss: 1.2697 - val_accuracy: 0.6294\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.2848 - accuracy: 0.6185 - val_loss: 1.2233 - val_accuracy: 0.6462\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.2527 - accuracy: 0.6328 - val_loss: 1.2030 - val_accuracy: 0.6527\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.2251 - accuracy: 0.6405 - val_loss: 1.1735 - val_accuracy: 0.6625\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 1.1983 - accuracy: 0.6506 - val_loss: 1.1488 - val_accuracy: 0.6702\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 1.1776 - accuracy: 0.6584 - val_loss: 1.1376 - val_accuracy: 0.6731\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.1513 - accuracy: 0.6657 - val_loss: 1.1011 - val_accuracy: 0.6855\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.1297 - accuracy: 0.6704 - val_loss: 1.0928 - val_accuracy: 0.6881\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.1093 - accuracy: 0.6773 - val_loss: 1.0558 - val_accuracy: 0.6992\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.0901 - accuracy: 0.6834 - val_loss: 1.0423 - val_accuracy: 0.7014\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.0743 - accuracy: 0.6889 - val_loss: 1.0250 - val_accuracy: 0.7087\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.0556 - accuracy: 0.6944 - val_loss: 1.0158 - val_accuracy: 0.7099\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.0369 - accuracy: 0.6990 - val_loss: 0.9958 - val_accuracy: 0.7165\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 1.0215 - accuracy: 0.7046 - val_loss: 0.9813 - val_accuracy: 0.7190\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 1.0072 - accuracy: 0.7084 - val_loss: 0.9644 - val_accuracy: 0.7249\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.9965 - accuracy: 0.7105 - val_loss: 0.9524 - val_accuracy: 0.7268\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.9785 - accuracy: 0.7173 - val_loss: 0.9357 - val_accuracy: 0.7326\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.9676 - accuracy: 0.7190 - val_loss: 0.9338 - val_accuracy: 0.7335\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.9547 - accuracy: 0.7214 - val_loss: 0.9134 - val_accuracy: 0.7380\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.9391 - accuracy: 0.7265 - val_loss: 0.9007 - val_accuracy: 0.7419\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.9291 - accuracy: 0.7302 - val_loss: 0.8908 - val_accuracy: 0.7438\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.9154 - accuracy: 0.7349 - val_loss: 0.8845 - val_accuracy: 0.7458\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.9101 - accuracy: 0.7353 - val_loss: 0.8663 - val_accuracy: 0.7541\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.8961 - accuracy: 0.7385 - val_loss: 0.8619 - val_accuracy: 0.7498\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.8863 - accuracy: 0.7430 - val_loss: 0.8461 - val_accuracy: 0.7571\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.8759 - accuracy: 0.7443 - val_loss: 0.8364 - val_accuracy: 0.7611\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.8655 - accuracy: 0.7470 - val_loss: 0.8280 - val_accuracy: 0.7618\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.8535 - accuracy: 0.7513 - val_loss: 0.8277 - val_accuracy: 0.7645\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.8448 - accuracy: 0.7556 - val_loss: 0.8104 - val_accuracy: 0.7667\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.8392 - accuracy: 0.7550 - val_loss: 0.7994 - val_accuracy: 0.7731\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 6s 15ms/step - loss: 0.8296 - accuracy: 0.7570 - val_loss: 0.7963 - val_accuracy: 0.7728\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.8222 - accuracy: 0.7607 - val_loss: 0.7848 - val_accuracy: 0.7757\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.8107 - accuracy: 0.7633 - val_loss: 0.7806 - val_accuracy: 0.7754\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.8012 - accuracy: 0.7665 - val_loss: 0.7773 - val_accuracy: 0.7747\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.7960 - accuracy: 0.7685 - val_loss: 0.7603 - val_accuracy: 0.7826\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.7885 - accuracy: 0.7727 - val_loss: 0.7553 - val_accuracy: 0.7838\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.7836 - accuracy: 0.7714 - val_loss: 0.7507 - val_accuracy: 0.7847\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.7735 - accuracy: 0.7745 - val_loss: 0.7448 - val_accuracy: 0.7860\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.7661 - accuracy: 0.7760 - val_loss: 0.7326 - val_accuracy: 0.7907\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.7579 - accuracy: 0.7779 - val_loss: 0.7332 - val_accuracy: 0.7885\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.7534 - accuracy: 0.7799 - val_loss: 0.7287 - val_accuracy: 0.7897\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.7442 - accuracy: 0.7832 - val_loss: 0.7281 - val_accuracy: 0.7897\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.7359 - accuracy: 0.7850 - val_loss: 0.7126 - val_accuracy: 0.7958\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.7320 - accuracy: 0.7860 - val_loss: 0.7157 - val_accuracy: 0.7951\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.7239 - accuracy: 0.7874 - val_loss: 0.7088 - val_accuracy: 0.7951\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.7201 - accuracy: 0.7890 - val_loss: 0.6894 - val_accuracy: 0.8021\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.7130 - accuracy: 0.7915 - val_loss: 0.7032 - val_accuracy: 0.7952\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.7048 - accuracy: 0.7947 - val_loss: 0.6893 - val_accuracy: 0.8026\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.7001 - accuracy: 0.7953 - val_loss: 0.6813 - val_accuracy: 0.8025\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 9s 21ms/step - loss: 0.6977 - accuracy: 0.7973 - val_loss: 0.6747 - val_accuracy: 0.8061\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6855 - accuracy: 0.7993 - val_loss: 0.6774 - val_accuracy: 0.8055\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6849 - accuracy: 0.8001 - val_loss: 0.6757 - val_accuracy: 0.8059\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6769 - accuracy: 0.8014 - val_loss: 0.6560 - val_accuracy: 0.8102\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.6750 - accuracy: 0.8020 - val_loss: 0.6606 - val_accuracy: 0.8101\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.6657 - accuracy: 0.8060 - val_loss: 0.6583 - val_accuracy: 0.8114\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.6639 - accuracy: 0.8074 - val_loss: 0.6425 - val_accuracy: 0.8153\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.6561 - accuracy: 0.8099 - val_loss: 0.6442 - val_accuracy: 0.8156\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6513 - accuracy: 0.8106 - val_loss: 0.6421 - val_accuracy: 0.8144\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.6443 - accuracy: 0.8123 - val_loss: 0.6257 - val_accuracy: 0.8208\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6445 - accuracy: 0.8109 - val_loss: 0.6191 - val_accuracy: 0.8232\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6374 - accuracy: 0.8144 - val_loss: 0.6340 - val_accuracy: 0.8160\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6351 - accuracy: 0.8156 - val_loss: 0.6190 - val_accuracy: 0.8240\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6282 - accuracy: 0.8169 - val_loss: 0.6259 - val_accuracy: 0.8171\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6251 - accuracy: 0.8197 - val_loss: 0.6055 - val_accuracy: 0.8267\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6171 - accuracy: 0.8209 - val_loss: 0.6274 - val_accuracy: 0.8163\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.6135 - accuracy: 0.8210 - val_loss: 0.6073 - val_accuracy: 0.8249\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.6090 - accuracy: 0.8229 - val_loss: 0.5982 - val_accuracy: 0.8286\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.6050 - accuracy: 0.8233 - val_loss: 0.5951 - val_accuracy: 0.8300\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5990 - accuracy: 0.8243 - val_loss: 0.6005 - val_accuracy: 0.8273\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.5954 - accuracy: 0.8261 - val_loss: 0.5890 - val_accuracy: 0.8311\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.5931 - accuracy: 0.8277 - val_loss: 0.5811 - val_accuracy: 0.8343\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.5854 - accuracy: 0.8287 - val_loss: 0.5759 - val_accuracy: 0.8373\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5864 - accuracy: 0.8293 - val_loss: 0.5778 - val_accuracy: 0.8352\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.5802 - accuracy: 0.8309 - val_loss: 0.5740 - val_accuracy: 0.8332\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5783 - accuracy: 0.8318 - val_loss: 0.5628 - val_accuracy: 0.8400\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5721 - accuracy: 0.8332 - val_loss: 0.5684 - val_accuracy: 0.8364\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5682 - accuracy: 0.8332 - val_loss: 0.5635 - val_accuracy: 0.8378\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5623 - accuracy: 0.8367 - val_loss: 0.5673 - val_accuracy: 0.8366\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5597 - accuracy: 0.8363 - val_loss: 0.5636 - val_accuracy: 0.8381\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5579 - accuracy: 0.8379 - val_loss: 0.5647 - val_accuracy: 0.8390\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.5513 - accuracy: 0.8385 - val_loss: 0.5680 - val_accuracy: 0.8338\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.5493 - accuracy: 0.8389 - val_loss: 0.5599 - val_accuracy: 0.8389\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.5489 - accuracy: 0.8401 - val_loss: 0.5491 - val_accuracy: 0.8420\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5433 - accuracy: 0.8420 - val_loss: 0.5427 - val_accuracy: 0.8453\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 5s 13ms/step - loss: 0.5389 - accuracy: 0.8427 - val_loss: 0.5376 - val_accuracy: 0.8482\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.5353 - accuracy: 0.8439 - val_loss: 0.5315 - val_accuracy: 0.8508\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 6s 14ms/step - loss: 0.5300 - accuracy: 0.8463 - val_loss: 0.5199 - val_accuracy: 0.8533\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 6s 13ms/step - loss: 0.5269 - accuracy: 0.8462 - val_loss: 0.5286 - val_accuracy: 0.8475\n"
     ]
    }
   ],
   "source": [
    "model8 = mlp_model8()\n",
    "history8 = model8.fit(X_train, y_train, batch_size = 100, validation_data=(X_val, y_val), epochs = 100, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "buWG0zo4pTVJ",
    "outputId": "0561f748-728c-4c51-cc6f-acd61740bc25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 0.6974 - accuracy: 0.7913\n"
     ]
    }
   ],
   "source": [
    "Results8 = model8.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "325CVbHBpAsp"
   },
   "source": [
    "Again accuracy increases from 78.14% to 79.13%. But now the model seems to be startin to over fit. Thus, we can go with 100 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpTT3uqeqxlc"
   },
   "source": [
    "#3. Change learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_GxkP-XLtQt"
   },
   "outputs": [],
   "source": [
    "#Changing learning rate to 0.0001\n",
    "def mlp_model5():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(100, input_shape = (1024, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr = 0.0001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6o_KFHV-NQL5",
    "outputId": "9cf57088-c0d0-445f-d6be-59a2efd3eb96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.7133 - accuracy: 0.0975 - val_loss: 2.5943 - val_accuracy: 0.1012\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.6797 - accuracy: 0.1054 - val_loss: 2.6637 - val_accuracy: 0.1086\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.6419 - accuracy: 0.1109 - val_loss: 2.6364 - val_accuracy: 0.1143\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.6099 - accuracy: 0.1143 - val_loss: 2.6036 - val_accuracy: 0.1211\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.5769 - accuracy: 0.1225 - val_loss: 2.5683 - val_accuracy: 0.1242\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.5473 - accuracy: 0.1268 - val_loss: 2.5354 - val_accuracy: 0.1295\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.5214 - accuracy: 0.1300 - val_loss: 2.5105 - val_accuracy: 0.1349\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.4919 - accuracy: 0.1377 - val_loss: 2.4831 - val_accuracy: 0.1407\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.4690 - accuracy: 0.1427 - val_loss: 2.4525 - val_accuracy: 0.1471\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.4422 - accuracy: 0.1475 - val_loss: 2.4252 - val_accuracy: 0.1512\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.4165 - accuracy: 0.1543 - val_loss: 2.4011 - val_accuracy: 0.1591\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.3893 - accuracy: 0.1619 - val_loss: 2.3774 - val_accuracy: 0.1653\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.3710 - accuracy: 0.1635 - val_loss: 2.3533 - val_accuracy: 0.1716\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.3452 - accuracy: 0.1736 - val_loss: 2.3295 - val_accuracy: 0.1777\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.3270 - accuracy: 0.1797 - val_loss: 2.3107 - val_accuracy: 0.1852\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.3043 - accuracy: 0.1852 - val_loss: 2.2884 - val_accuracy: 0.1919\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.2832 - accuracy: 0.1915 - val_loss: 2.2655 - val_accuracy: 0.1979\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.2625 - accuracy: 0.1976 - val_loss: 2.2470 - val_accuracy: 0.2053\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.2439 - accuracy: 0.2038 - val_loss: 2.2241 - val_accuracy: 0.2114\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.2254 - accuracy: 0.2095 - val_loss: 2.2080 - val_accuracy: 0.2184\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.2066 - accuracy: 0.2162 - val_loss: 2.1867 - val_accuracy: 0.2254\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.1889 - accuracy: 0.2247 - val_loss: 2.1687 - val_accuracy: 0.2322\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.1682 - accuracy: 0.2317 - val_loss: 2.1528 - val_accuracy: 0.2363\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.1524 - accuracy: 0.2379 - val_loss: 2.1357 - val_accuracy: 0.2435\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.1380 - accuracy: 0.2437 - val_loss: 2.1163 - val_accuracy: 0.2519\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.1223 - accuracy: 0.2486 - val_loss: 2.1023 - val_accuracy: 0.2573\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.1087 - accuracy: 0.2545 - val_loss: 2.0863 - val_accuracy: 0.2625\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.0902 - accuracy: 0.2638 - val_loss: 2.0709 - val_accuracy: 0.2690\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.0777 - accuracy: 0.2691 - val_loss: 2.0561 - val_accuracy: 0.2743\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.0649 - accuracy: 0.2721 - val_loss: 2.0436 - val_accuracy: 0.2812\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 2.0513 - accuracy: 0.2800 - val_loss: 2.0269 - val_accuracy: 0.2881\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.0375 - accuracy: 0.2836 - val_loss: 2.0147 - val_accuracy: 0.2927\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.0252 - accuracy: 0.2893 - val_loss: 2.0018 - val_accuracy: 0.2990\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 2.0125 - accuracy: 0.2933 - val_loss: 1.9889 - val_accuracy: 0.3059\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9991 - accuracy: 0.2997 - val_loss: 1.9745 - val_accuracy: 0.3124\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9864 - accuracy: 0.3058 - val_loss: 1.9611 - val_accuracy: 0.3180\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9741 - accuracy: 0.3123 - val_loss: 1.9513 - val_accuracy: 0.3216\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9649 - accuracy: 0.3158 - val_loss: 1.9389 - val_accuracy: 0.3275\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.9522 - accuracy: 0.3222 - val_loss: 1.9272 - val_accuracy: 0.3333\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9417 - accuracy: 0.3267 - val_loss: 1.9171 - val_accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9303 - accuracy: 0.3328 - val_loss: 1.9044 - val_accuracy: 0.3443\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.9166 - accuracy: 0.3363 - val_loss: 1.8962 - val_accuracy: 0.3479\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9093 - accuracy: 0.3385 - val_loss: 1.8833 - val_accuracy: 0.3528\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.9013 - accuracy: 0.3424 - val_loss: 1.8721 - val_accuracy: 0.3593\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8894 - accuracy: 0.3496 - val_loss: 1.8640 - val_accuracy: 0.3635\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8804 - accuracy: 0.3543 - val_loss: 1.8542 - val_accuracy: 0.3681\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8711 - accuracy: 0.3592 - val_loss: 1.8434 - val_accuracy: 0.3719\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8621 - accuracy: 0.3624 - val_loss: 1.8342 - val_accuracy: 0.3773\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8487 - accuracy: 0.3717 - val_loss: 1.8226 - val_accuracy: 0.3826\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8441 - accuracy: 0.3710 - val_loss: 1.8149 - val_accuracy: 0.3862\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.8325 - accuracy: 0.3748 - val_loss: 1.8050 - val_accuracy: 0.3919\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8256 - accuracy: 0.3808 - val_loss: 1.7972 - val_accuracy: 0.3960\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8156 - accuracy: 0.3840 - val_loss: 1.7898 - val_accuracy: 0.3997\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8070 - accuracy: 0.3883 - val_loss: 1.7828 - val_accuracy: 0.4036\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.8010 - accuracy: 0.3927 - val_loss: 1.7709 - val_accuracy: 0.4089\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.7927 - accuracy: 0.3960 - val_loss: 1.7640 - val_accuracy: 0.4114\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7821 - accuracy: 0.4028 - val_loss: 1.7538 - val_accuracy: 0.4162\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7799 - accuracy: 0.4019 - val_loss: 1.7490 - val_accuracy: 0.4189\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7693 - accuracy: 0.4081 - val_loss: 1.7380 - val_accuracy: 0.4242\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7642 - accuracy: 0.4087 - val_loss: 1.7297 - val_accuracy: 0.4270\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7523 - accuracy: 0.4162 - val_loss: 1.7243 - val_accuracy: 0.4310\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7469 - accuracy: 0.4186 - val_loss: 1.7190 - val_accuracy: 0.4349\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7390 - accuracy: 0.4236 - val_loss: 1.7134 - val_accuracy: 0.4353\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.7317 - accuracy: 0.4261 - val_loss: 1.7032 - val_accuracy: 0.4421\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7235 - accuracy: 0.4309 - val_loss: 1.6956 - val_accuracy: 0.4465\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.7193 - accuracy: 0.4304 - val_loss: 1.6895 - val_accuracy: 0.4491\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.7092 - accuracy: 0.4377 - val_loss: 1.6817 - val_accuracy: 0.4533\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.7070 - accuracy: 0.4373 - val_loss: 1.6742 - val_accuracy: 0.4569\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.7007 - accuracy: 0.4392 - val_loss: 1.6714 - val_accuracy: 0.4582\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.6920 - accuracy: 0.4437 - val_loss: 1.6635 - val_accuracy: 0.4620\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6867 - accuracy: 0.4486 - val_loss: 1.6576 - val_accuracy: 0.4656\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6808 - accuracy: 0.4532 - val_loss: 1.6477 - val_accuracy: 0.4692\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6787 - accuracy: 0.4525 - val_loss: 1.6460 - val_accuracy: 0.4700\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.6684 - accuracy: 0.4557 - val_loss: 1.6398 - val_accuracy: 0.4721\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.6628 - accuracy: 0.4600 - val_loss: 1.6311 - val_accuracy: 0.4783\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6564 - accuracy: 0.4622 - val_loss: 1.6262 - val_accuracy: 0.4794\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6542 - accuracy: 0.4613 - val_loss: 1.6222 - val_accuracy: 0.4821\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6479 - accuracy: 0.4655 - val_loss: 1.6167 - val_accuracy: 0.4849\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6398 - accuracy: 0.4697 - val_loss: 1.6100 - val_accuracy: 0.4872\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6364 - accuracy: 0.4700 - val_loss: 1.6015 - val_accuracy: 0.4911\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6308 - accuracy: 0.4748 - val_loss: 1.5965 - val_accuracy: 0.4946\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.6257 - accuracy: 0.4755 - val_loss: 1.5922 - val_accuracy: 0.4955\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.6193 - accuracy: 0.4791 - val_loss: 1.5852 - val_accuracy: 0.4990\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.6155 - accuracy: 0.4800 - val_loss: 1.5811 - val_accuracy: 0.5013\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 4s 10ms/step - loss: 1.6092 - accuracy: 0.4851 - val_loss: 1.5762 - val_accuracy: 0.5042\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 1.6025 - accuracy: 0.4877 - val_loss: 1.5730 - val_accuracy: 0.5055\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5998 - accuracy: 0.4888 - val_loss: 1.5656 - val_accuracy: 0.5087\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.5945 - accuracy: 0.4896 - val_loss: 1.5603 - val_accuracy: 0.5115\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5907 - accuracy: 0.4922 - val_loss: 1.5590 - val_accuracy: 0.5117\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5854 - accuracy: 0.4935 - val_loss: 1.5516 - val_accuracy: 0.5145\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5805 - accuracy: 0.4965 - val_loss: 1.5448 - val_accuracy: 0.5172\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5764 - accuracy: 0.4980 - val_loss: 1.5425 - val_accuracy: 0.5180\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5709 - accuracy: 0.5039 - val_loss: 1.5376 - val_accuracy: 0.5203\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.5683 - accuracy: 0.5023 - val_loss: 1.5319 - val_accuracy: 0.5230\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5627 - accuracy: 0.5037 - val_loss: 1.5272 - val_accuracy: 0.5253\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5576 - accuracy: 0.5068 - val_loss: 1.5253 - val_accuracy: 0.5267\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5558 - accuracy: 0.5048 - val_loss: 1.5213 - val_accuracy: 0.5283\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5504 - accuracy: 0.5098 - val_loss: 1.5109 - val_accuracy: 0.5321\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.5439 - accuracy: 0.5116 - val_loss: 1.5077 - val_accuracy: 0.5336\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 1.5392 - accuracy: 0.5155 - val_loss: 1.5052 - val_accuracy: 0.5351\n"
     ]
    }
   ],
   "source": [
    "model5 = mlp_model5()\n",
    "history5 = model5.fit(X_train, y_train, batch_size=100, validation_data=(X_val, y_val), epochs = 100, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RRv_-WWAZkee",
    "outputId": "45890130-7898-4c3f-808d-37559f534cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 1.5246 - accuracy: 0.5259\n"
     ]
    }
   ],
   "source": [
    "Results5 = model5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIGd49x5tOND"
   },
   "source": [
    "Accuracy seems to dip from 78.14% to 52.59% which indicates this is not good learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcNBimeMaMaW"
   },
   "outputs": [],
   "source": [
    "#Changing learning rate to 0.01\n",
    "def mlp_model6():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(100, input_shape = (1024, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = optimizers.SGD(lr = 0.01)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eZOESKWdcOD5",
    "outputId": "c7ec3cff-6f8b-487b-de2f-834fdf7b7ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.9550 - accuracy: 0.3365 - val_loss: 1.7512 - val_accuracy: 0.4227\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.4002 - accuracy: 0.5658 - val_loss: 1.4131 - val_accuracy: 0.5601\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.1973 - accuracy: 0.6377 - val_loss: 1.2123 - val_accuracy: 0.6242\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.0814 - accuracy: 0.6723 - val_loss: 1.1925 - val_accuracy: 0.6279\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.9996 - accuracy: 0.6965 - val_loss: 1.1328 - val_accuracy: 0.6442\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9400 - accuracy: 0.7139 - val_loss: 1.0855 - val_accuracy: 0.6559\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.8861 - accuracy: 0.7302 - val_loss: 1.0223 - val_accuracy: 0.6774\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.8448 - accuracy: 0.7415 - val_loss: 0.9685 - val_accuracy: 0.6994\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.8051 - accuracy: 0.7525 - val_loss: 1.0683 - val_accuracy: 0.6610\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.7744 - accuracy: 0.7632 - val_loss: 0.8443 - val_accuracy: 0.7378\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.7502 - accuracy: 0.7679 - val_loss: 1.3274 - val_accuracy: 0.5917\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.7228 - accuracy: 0.7777 - val_loss: 0.9287 - val_accuracy: 0.7106\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6968 - accuracy: 0.7858 - val_loss: 0.8868 - val_accuracy: 0.7265\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.6791 - accuracy: 0.7903 - val_loss: 0.8665 - val_accuracy: 0.7286\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.6609 - accuracy: 0.7962 - val_loss: 0.8027 - val_accuracy: 0.7490\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6382 - accuracy: 0.8028 - val_loss: 0.7635 - val_accuracy: 0.7635\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6303 - accuracy: 0.8053 - val_loss: 0.9456 - val_accuracy: 0.7058\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6123 - accuracy: 0.8104 - val_loss: 0.6691 - val_accuracy: 0.7956\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.6014 - accuracy: 0.8125 - val_loss: 0.8916 - val_accuracy: 0.7207\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5843 - accuracy: 0.8169 - val_loss: 0.8175 - val_accuracy: 0.7404\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.5764 - accuracy: 0.8208 - val_loss: 0.7928 - val_accuracy: 0.7557\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.5649 - accuracy: 0.8236 - val_loss: 0.8313 - val_accuracy: 0.7319\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5553 - accuracy: 0.8267 - val_loss: 0.7614 - val_accuracy: 0.7569\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5427 - accuracy: 0.8294 - val_loss: 0.7149 - val_accuracy: 0.7757\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5358 - accuracy: 0.8324 - val_loss: 0.6988 - val_accuracy: 0.7846\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.5262 - accuracy: 0.8342 - val_loss: 0.8154 - val_accuracy: 0.7404\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5181 - accuracy: 0.8407 - val_loss: 0.7495 - val_accuracy: 0.7625\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5145 - accuracy: 0.8402 - val_loss: 0.6797 - val_accuracy: 0.7857\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5026 - accuracy: 0.8405 - val_loss: 0.6737 - val_accuracy: 0.7881\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5004 - accuracy: 0.8420 - val_loss: 1.1116 - val_accuracy: 0.6725\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4902 - accuracy: 0.8456 - val_loss: 0.8131 - val_accuracy: 0.7419\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.4849 - accuracy: 0.8490 - val_loss: 0.6404 - val_accuracy: 0.7972\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4727 - accuracy: 0.8534 - val_loss: 0.6741 - val_accuracy: 0.7924\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4702 - accuracy: 0.8525 - val_loss: 0.8554 - val_accuracy: 0.7383\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.4653 - accuracy: 0.8540 - val_loss: 0.6127 - val_accuracy: 0.8076\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4596 - accuracy: 0.8546 - val_loss: 0.6222 - val_accuracy: 0.8063\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4498 - accuracy: 0.8609 - val_loss: 0.5934 - val_accuracy: 0.8139\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4408 - accuracy: 0.8621 - val_loss: 0.8359 - val_accuracy: 0.7459\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.4396 - accuracy: 0.8617 - val_loss: 0.6380 - val_accuracy: 0.7992\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.4277 - accuracy: 0.8655 - val_loss: 0.6015 - val_accuracy: 0.8115\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4219 - accuracy: 0.8679 - val_loss: 0.6317 - val_accuracy: 0.8038\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4203 - accuracy: 0.8666 - val_loss: 0.6916 - val_accuracy: 0.7873\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4131 - accuracy: 0.8704 - val_loss: 0.6688 - val_accuracy: 0.7959\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4081 - accuracy: 0.8715 - val_loss: 0.6933 - val_accuracy: 0.7866\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.4072 - accuracy: 0.8714 - val_loss: 0.6293 - val_accuracy: 0.8049\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.4067 - accuracy: 0.8726 - val_loss: 0.6609 - val_accuracy: 0.7991\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.3989 - accuracy: 0.8739 - val_loss: 0.5726 - val_accuracy: 0.8205\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.3923 - accuracy: 0.8760 - val_loss: 0.6274 - val_accuracy: 0.8083\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3913 - accuracy: 0.8754 - val_loss: 0.6730 - val_accuracy: 0.7898\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3885 - accuracy: 0.8772 - val_loss: 0.8301 - val_accuracy: 0.7517\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.3852 - accuracy: 0.8779 - val_loss: 0.6776 - val_accuracy: 0.7967\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3790 - accuracy: 0.8806 - val_loss: 0.6747 - val_accuracy: 0.7883\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3750 - accuracy: 0.8812 - val_loss: 0.5560 - val_accuracy: 0.8268\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3714 - accuracy: 0.8812 - val_loss: 0.7788 - val_accuracy: 0.7650\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3665 - accuracy: 0.8844 - val_loss: 0.6347 - val_accuracy: 0.8055\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3608 - accuracy: 0.8863 - val_loss: 0.6945 - val_accuracy: 0.7851\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3649 - accuracy: 0.8831 - val_loss: 0.6991 - val_accuracy: 0.7886\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3546 - accuracy: 0.8871 - val_loss: 0.6297 - val_accuracy: 0.8057\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3523 - accuracy: 0.8884 - val_loss: 0.5870 - val_accuracy: 0.8218\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.3496 - accuracy: 0.8897 - val_loss: 0.6349 - val_accuracy: 0.8036\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.3424 - accuracy: 0.8928 - val_loss: 0.5189 - val_accuracy: 0.8421\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3403 - accuracy: 0.8910 - val_loss: 0.6289 - val_accuracy: 0.8075\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.3372 - accuracy: 0.8932 - val_loss: 0.5049 - val_accuracy: 0.8443\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3350 - accuracy: 0.8944 - val_loss: 0.6437 - val_accuracy: 0.8023\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3294 - accuracy: 0.8953 - val_loss: 0.4714 - val_accuracy: 0.8559\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.3249 - accuracy: 0.8970 - val_loss: 0.7000 - val_accuracy: 0.7988\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3315 - accuracy: 0.8955 - val_loss: 0.5605 - val_accuracy: 0.8281\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3198 - accuracy: 0.8990 - val_loss: 0.5704 - val_accuracy: 0.8278\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3205 - accuracy: 0.8979 - val_loss: 0.5954 - val_accuracy: 0.8176\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3191 - accuracy: 0.9004 - val_loss: 0.6194 - val_accuracy: 0.8101\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3184 - accuracy: 0.8991 - val_loss: 0.8974 - val_accuracy: 0.7330\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3162 - accuracy: 0.8992 - val_loss: 0.6048 - val_accuracy: 0.8166\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3079 - accuracy: 0.9021 - val_loss: 0.6806 - val_accuracy: 0.7967\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3101 - accuracy: 0.8999 - val_loss: 0.5769 - val_accuracy: 0.8244\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3092 - accuracy: 0.9017 - val_loss: 0.7342 - val_accuracy: 0.7968\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3023 - accuracy: 0.9037 - val_loss: 0.5288 - val_accuracy: 0.8392\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.3046 - accuracy: 0.9035 - val_loss: 0.5784 - val_accuracy: 0.8283\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2935 - accuracy: 0.9067 - val_loss: 0.9293 - val_accuracy: 0.7486\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2926 - accuracy: 0.9072 - val_loss: 0.4781 - val_accuracy: 0.8535\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.2946 - accuracy: 0.9060 - val_loss: 0.4164 - val_accuracy: 0.8771\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2885 - accuracy: 0.9082 - val_loss: 0.5175 - val_accuracy: 0.8431\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2916 - accuracy: 0.9075 - val_loss: 0.4379 - val_accuracy: 0.8709\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2872 - accuracy: 0.9093 - val_loss: 0.5198 - val_accuracy: 0.8433\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2828 - accuracy: 0.9088 - val_loss: 0.5955 - val_accuracy: 0.8221\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.2812 - accuracy: 0.9100 - val_loss: 0.6757 - val_accuracy: 0.7961\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.2799 - accuracy: 0.9111 - val_loss: 0.5359 - val_accuracy: 0.8411\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.2775 - accuracy: 0.9115 - val_loss: 0.4650 - val_accuracy: 0.8614\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2749 - accuracy: 0.9128 - val_loss: 0.7726 - val_accuracy: 0.7829\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.2723 - accuracy: 0.9117 - val_loss: 0.4901 - val_accuracy: 0.8543\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2712 - accuracy: 0.9137 - val_loss: 0.4737 - val_accuracy: 0.8594\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2691 - accuracy: 0.9149 - val_loss: 0.4463 - val_accuracy: 0.8644\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.2664 - accuracy: 0.9141 - val_loss: 0.5137 - val_accuracy: 0.8490\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2631 - accuracy: 0.9159 - val_loss: 0.5289 - val_accuracy: 0.8413\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2581 - accuracy: 0.9174 - val_loss: 0.5629 - val_accuracy: 0.8356\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2581 - accuracy: 0.9193 - val_loss: 0.5283 - val_accuracy: 0.8425\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2601 - accuracy: 0.9163 - val_loss: 0.5624 - val_accuracy: 0.8316\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2559 - accuracy: 0.9166 - val_loss: 0.4703 - val_accuracy: 0.8615\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2525 - accuracy: 0.9189 - val_loss: 0.4824 - val_accuracy: 0.8555\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2517 - accuracy: 0.9205 - val_loss: 0.4904 - val_accuracy: 0.8586\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.2507 - accuracy: 0.9194 - val_loss: 0.6415 - val_accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "model6 = mlp_model6()\n",
    "history6 = model6.fit(X_train, y_train, batch_size = 100, validation_data=(X_val, y_val), epochs = 100, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z4UMgDKYdbm2",
    "outputId": "df3f931c-cc68-4f4f-8ac2-d1bf4bb28d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 0.9374 - accuracy: 0.7504\n"
     ]
    }
   ],
   "source": [
    "Results6 = model6.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZuVn-u6Ptk_W"
   },
   "source": [
    "Here also accuracy dips from 78.14% to 75%. Thus it is better to have learning rate of 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDdeiNpptww9"
   },
   "source": [
    "#4. Using alternate kernel initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rK2fERvjVG-H"
   },
   "outputs": [],
   "source": [
    " def mlp_model7():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(100, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=0.001)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E62f5svNa3-0",
    "outputId": "ee9410b5-2dd0-47cb-c399-b42ce018f0a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0733 - accuracy: 0.6651 - val_loss: 1.0754 - val_accuracy: 0.6654\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0695 - accuracy: 0.6663 - val_loss: 1.0684 - val_accuracy: 0.6685\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0663 - accuracy: 0.6685 - val_loss: 1.0677 - val_accuracy: 0.6686\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0623 - accuracy: 0.6688 - val_loss: 1.0644 - val_accuracy: 0.6702\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0586 - accuracy: 0.6710 - val_loss: 1.0623 - val_accuracy: 0.6730\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0556 - accuracy: 0.6725 - val_loss: 1.0541 - val_accuracy: 0.6741\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0527 - accuracy: 0.6716 - val_loss: 1.0552 - val_accuracy: 0.6746\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0502 - accuracy: 0.6748 - val_loss: 1.0558 - val_accuracy: 0.6720\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0469 - accuracy: 0.6755 - val_loss: 1.0491 - val_accuracy: 0.6767\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0423 - accuracy: 0.6782 - val_loss: 1.0460 - val_accuracy: 0.6789\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0397 - accuracy: 0.6778 - val_loss: 1.0462 - val_accuracy: 0.6755\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0380 - accuracy: 0.6774 - val_loss: 1.0798 - val_accuracy: 0.6593\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0344 - accuracy: 0.6790 - val_loss: 1.0383 - val_accuracy: 0.6800\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0309 - accuracy: 0.6813 - val_loss: 1.0356 - val_accuracy: 0.6806\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0285 - accuracy: 0.6812 - val_loss: 1.0276 - val_accuracy: 0.6844\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0260 - accuracy: 0.6822 - val_loss: 1.0362 - val_accuracy: 0.6808\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0225 - accuracy: 0.6842 - val_loss: 1.0212 - val_accuracy: 0.6866\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0175 - accuracy: 0.6843 - val_loss: 1.0223 - val_accuracy: 0.6850\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0165 - accuracy: 0.6863 - val_loss: 1.0174 - val_accuracy: 0.6874\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0132 - accuracy: 0.6883 - val_loss: 1.0189 - val_accuracy: 0.6854\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0103 - accuracy: 0.6881 - val_loss: 1.0085 - val_accuracy: 0.6910\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0078 - accuracy: 0.6888 - val_loss: 1.0210 - val_accuracy: 0.6823\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0049 - accuracy: 0.6895 - val_loss: 1.0149 - val_accuracy: 0.6882\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 1.0021 - accuracy: 0.6904 - val_loss: 1.0024 - val_accuracy: 0.6942\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9991 - accuracy: 0.6919 - val_loss: 1.0011 - val_accuracy: 0.6912\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9962 - accuracy: 0.6935 - val_loss: 0.9981 - val_accuracy: 0.6924\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9934 - accuracy: 0.6931 - val_loss: 0.9926 - val_accuracy: 0.6968\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9917 - accuracy: 0.6938 - val_loss: 0.9947 - val_accuracy: 0.6953\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 2s 6ms/step - loss: 0.9889 - accuracy: 0.6945 - val_loss: 1.0010 - val_accuracy: 0.6902\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9863 - accuracy: 0.6983 - val_loss: 0.9875 - val_accuracy: 0.6971\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9832 - accuracy: 0.6975 - val_loss: 0.9993 - val_accuracy: 0.6933\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9799 - accuracy: 0.6996 - val_loss: 0.9911 - val_accuracy: 0.6973\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9781 - accuracy: 0.6984 - val_loss: 0.9867 - val_accuracy: 0.6978\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9759 - accuracy: 0.7005 - val_loss: 0.9854 - val_accuracy: 0.6968\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9726 - accuracy: 0.7002 - val_loss: 0.9788 - val_accuracy: 0.7012\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9705 - accuracy: 0.7022 - val_loss: 0.9758 - val_accuracy: 0.7005\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9679 - accuracy: 0.7029 - val_loss: 0.9679 - val_accuracy: 0.7051\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9643 - accuracy: 0.7045 - val_loss: 0.9717 - val_accuracy: 0.7041\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9609 - accuracy: 0.7064 - val_loss: 0.9647 - val_accuracy: 0.7071\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9605 - accuracy: 0.7065 - val_loss: 0.9684 - val_accuracy: 0.7058\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9580 - accuracy: 0.7066 - val_loss: 0.9656 - val_accuracy: 0.7047\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9556 - accuracy: 0.7068 - val_loss: 0.9702 - val_accuracy: 0.7008\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.9525 - accuracy: 0.7090 - val_loss: 0.9570 - val_accuracy: 0.7097\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.9510 - accuracy: 0.7085 - val_loss: 0.9544 - val_accuracy: 0.7097\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 3s 6ms/step - loss: 0.9478 - accuracy: 0.7106 - val_loss: 0.9600 - val_accuracy: 0.7055\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9446 - accuracy: 0.7115 - val_loss: 0.9550 - val_accuracy: 0.7118\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9436 - accuracy: 0.7113 - val_loss: 0.9488 - val_accuracy: 0.7133\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9403 - accuracy: 0.7124 - val_loss: 0.9498 - val_accuracy: 0.7122\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9380 - accuracy: 0.7136 - val_loss: 0.9479 - val_accuracy: 0.7123\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9358 - accuracy: 0.7135 - val_loss: 0.9437 - val_accuracy: 0.7160\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9331 - accuracy: 0.7154 - val_loss: 0.9426 - val_accuracy: 0.7127\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9311 - accuracy: 0.7161 - val_loss: 0.9447 - val_accuracy: 0.7121\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9292 - accuracy: 0.7173 - val_loss: 0.9335 - val_accuracy: 0.7183\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9259 - accuracy: 0.7188 - val_loss: 0.9400 - val_accuracy: 0.7136\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9246 - accuracy: 0.7190 - val_loss: 0.9277 - val_accuracy: 0.7183\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9223 - accuracy: 0.7191 - val_loss: 0.9288 - val_accuracy: 0.7201\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9210 - accuracy: 0.7184 - val_loss: 0.9281 - val_accuracy: 0.7170\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9172 - accuracy: 0.7202 - val_loss: 0.9240 - val_accuracy: 0.7213\n",
      "Epoch 59/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9159 - accuracy: 0.7211 - val_loss: 0.9202 - val_accuracy: 0.7232\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9132 - accuracy: 0.7213 - val_loss: 0.9170 - val_accuracy: 0.7241\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9115 - accuracy: 0.7243 - val_loss: 0.9160 - val_accuracy: 0.7214\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9087 - accuracy: 0.7233 - val_loss: 0.9248 - val_accuracy: 0.7210\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9074 - accuracy: 0.7230 - val_loss: 0.9144 - val_accuracy: 0.7230\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9054 - accuracy: 0.7244 - val_loss: 0.9166 - val_accuracy: 0.7221\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9028 - accuracy: 0.7265 - val_loss: 0.9095 - val_accuracy: 0.7247\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9011 - accuracy: 0.7263 - val_loss: 0.9144 - val_accuracy: 0.7208\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.9001 - accuracy: 0.7275 - val_loss: 0.9170 - val_accuracy: 0.7233\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8955 - accuracy: 0.7279 - val_loss: 0.9017 - val_accuracy: 0.7286\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8942 - accuracy: 0.7290 - val_loss: 0.9077 - val_accuracy: 0.7255\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8920 - accuracy: 0.7294 - val_loss: 0.8991 - val_accuracy: 0.7296\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8912 - accuracy: 0.7299 - val_loss: 0.8933 - val_accuracy: 0.7305\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8881 - accuracy: 0.7294 - val_loss: 0.8981 - val_accuracy: 0.7294\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8858 - accuracy: 0.7327 - val_loss: 0.8970 - val_accuracy: 0.7282\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8852 - accuracy: 0.7306 - val_loss: 0.8888 - val_accuracy: 0.7316\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8822 - accuracy: 0.7326 - val_loss: 0.8904 - val_accuracy: 0.7335\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8780 - accuracy: 0.7335 - val_loss: 0.8863 - val_accuracy: 0.7322\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8766 - accuracy: 0.7356 - val_loss: 0.8826 - val_accuracy: 0.7333\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8759 - accuracy: 0.7331 - val_loss: 0.8846 - val_accuracy: 0.7329\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8738 - accuracy: 0.7345 - val_loss: 0.8894 - val_accuracy: 0.7302\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8717 - accuracy: 0.7368 - val_loss: 0.8833 - val_accuracy: 0.7325\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8689 - accuracy: 0.7362 - val_loss: 0.8825 - val_accuracy: 0.7340\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8674 - accuracy: 0.7377 - val_loss: 0.8836 - val_accuracy: 0.7318\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8673 - accuracy: 0.7371 - val_loss: 0.8736 - val_accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8646 - accuracy: 0.7392 - val_loss: 0.8741 - val_accuracy: 0.7375\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8624 - accuracy: 0.7386 - val_loss: 0.8718 - val_accuracy: 0.7381\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8606 - accuracy: 0.7389 - val_loss: 0.8739 - val_accuracy: 0.7357\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8599 - accuracy: 0.7399 - val_loss: 0.8742 - val_accuracy: 0.7384\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8563 - accuracy: 0.7408 - val_loss: 0.8622 - val_accuracy: 0.7417\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8551 - accuracy: 0.7409 - val_loss: 0.8698 - val_accuracy: 0.7387\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8536 - accuracy: 0.7423 - val_loss: 0.8649 - val_accuracy: 0.7423\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8520 - accuracy: 0.7417 - val_loss: 0.8638 - val_accuracy: 0.7423\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8489 - accuracy: 0.7428 - val_loss: 0.8615 - val_accuracy: 0.7397\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8478 - accuracy: 0.7433 - val_loss: 0.8586 - val_accuracy: 0.7418\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8455 - accuracy: 0.7436 - val_loss: 0.8615 - val_accuracy: 0.7436\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8456 - accuracy: 0.7426 - val_loss: 0.8535 - val_accuracy: 0.7445\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8437 - accuracy: 0.7454 - val_loss: 0.8496 - val_accuracy: 0.7464\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8400 - accuracy: 0.7446 - val_loss: 0.8617 - val_accuracy: 0.7398\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8378 - accuracy: 0.7474 - val_loss: 0.8505 - val_accuracy: 0.7461\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8376 - accuracy: 0.7467 - val_loss: 0.8479 - val_accuracy: 0.7453\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 2s 5ms/step - loss: 0.8368 - accuracy: 0.7469 - val_loss: 0.8549 - val_accuracy: 0.7420\n"
     ]
    }
   ],
   "source": [
    " # Fit the model\n",
    "\n",
    "model7 = mlp_model7()\n",
    "history7 = model.fit(X_train, y_train, batch_size = 100, validation_data=(X_val, y_val), epochs = 100, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hzPyZal2j3Hy",
    "outputId": "9e4735c1-8266-41fc-ce97-ce8d72db9c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 2.4315 - accuracy: 0.1038\n"
     ]
    }
   ],
   "source": [
    "Results7 = model7.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vw4RV3Uot53N"
   },
   "source": [
    "Clearly the accuracy dips very low with he_normal kernel initializer. The default Glorot initializer seems to be performing better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_319O48vHHV"
   },
   "source": [
    "#5. Change lambda values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0sIaeYzf7Qq"
   },
   "outputs": [],
   "source": [
    "def train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 100\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hidden_nodes, input_shape = (1024, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(hidden_nodes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(output_nodes, kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=iterations, validation_data=(X_val, y_val), batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aAwRfzg1xUuv",
    "outputId": "a4367662-43eb-4fa3-b98a-98493bd3b080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.6277 - accuracy: 0.1150 - val_loss: 2.3608 - val_accuracy: 0.1040\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.3765 - accuracy: 0.1649 - val_loss: 2.3486 - val_accuracy: 0.1137\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.2234 - accuracy: 0.2157 - val_loss: 2.3094 - val_accuracy: 0.1313\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 2.1116 - accuracy: 0.2633 - val_loss: 2.2607 - val_accuracy: 0.1724\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.0171 - accuracy: 0.3097 - val_loss: 2.2068 - val_accuracy: 0.2213\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.9288 - accuracy: 0.3533 - val_loss: 2.1332 - val_accuracy: 0.2697\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.8431 - accuracy: 0.3955 - val_loss: 2.0578 - val_accuracy: 0.3049\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.7591 - accuracy: 0.4342 - val_loss: 1.9377 - val_accuracy: 0.3619\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6814 - accuracy: 0.4722 - val_loss: 1.8378 - val_accuracy: 0.4040\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6113 - accuracy: 0.5034 - val_loss: 1.7324 - val_accuracy: 0.4519\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5504 - accuracy: 0.5330 - val_loss: 1.6342 - val_accuracy: 0.4939\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4957 - accuracy: 0.5567 - val_loss: 1.5692 - val_accuracy: 0.5179\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4485 - accuracy: 0.5765 - val_loss: 1.5106 - val_accuracy: 0.5437\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4049 - accuracy: 0.5941 - val_loss: 1.4669 - val_accuracy: 0.5579\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.3667 - accuracy: 0.6093 - val_loss: 1.3977 - val_accuracy: 0.5847\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.3318 - accuracy: 0.6195 - val_loss: 1.3591 - val_accuracy: 0.5988\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2973 - accuracy: 0.6317 - val_loss: 1.3267 - val_accuracy: 0.6157\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.2669 - accuracy: 0.6409 - val_loss: 1.2927 - val_accuracy: 0.6244\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 1.2400 - accuracy: 0.6504 - val_loss: 1.2688 - val_accuracy: 0.6320\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.2138 - accuracy: 0.6559 - val_loss: 1.2367 - val_accuracy: 0.6433\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.1892 - accuracy: 0.6650 - val_loss: 1.2102 - val_accuracy: 0.6519\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 1.1663 - accuracy: 0.6714 - val_loss: 1.1811 - val_accuracy: 0.6633\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1443 - accuracy: 0.6767 - val_loss: 1.1658 - val_accuracy: 0.6658\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1240 - accuracy: 0.6841 - val_loss: 1.1483 - val_accuracy: 0.6688\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1040 - accuracy: 0.6894 - val_loss: 1.1302 - val_accuracy: 0.6768\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0855 - accuracy: 0.6941 - val_loss: 1.1180 - val_accuracy: 0.6781\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0685 - accuracy: 0.6985 - val_loss: 1.0990 - val_accuracy: 0.6858\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0523 - accuracy: 0.7038 - val_loss: 1.0831 - val_accuracy: 0.6892\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0361 - accuracy: 0.7079 - val_loss: 1.0711 - val_accuracy: 0.6931\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0201 - accuracy: 0.7126 - val_loss: 1.0459 - val_accuracy: 0.6989\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0065 - accuracy: 0.7161 - val_loss: 1.0268 - val_accuracy: 0.7049\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9928 - accuracy: 0.7212 - val_loss: 1.0288 - val_accuracy: 0.7018\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9805 - accuracy: 0.7235 - val_loss: 0.9975 - val_accuracy: 0.7127\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9672 - accuracy: 0.7267 - val_loss: 0.9938 - val_accuracy: 0.7131\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9551 - accuracy: 0.7294 - val_loss: 0.9807 - val_accuracy: 0.7202\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9428 - accuracy: 0.7327 - val_loss: 0.9723 - val_accuracy: 0.7214\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9309 - accuracy: 0.7371 - val_loss: 0.9638 - val_accuracy: 0.7218\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9220 - accuracy: 0.7377 - val_loss: 0.9502 - val_accuracy: 0.7280\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9109 - accuracy: 0.7415 - val_loss: 0.9461 - val_accuracy: 0.7288\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9015 - accuracy: 0.7443 - val_loss: 0.9340 - val_accuracy: 0.7304\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8903 - accuracy: 0.7465 - val_loss: 0.9296 - val_accuracy: 0.7324\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8797 - accuracy: 0.7498 - val_loss: 0.9175 - val_accuracy: 0.7359\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8721 - accuracy: 0.7527 - val_loss: 0.9107 - val_accuracy: 0.7354\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8619 - accuracy: 0.7546 - val_loss: 0.8950 - val_accuracy: 0.7426\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8540 - accuracy: 0.7583 - val_loss: 0.8904 - val_accuracy: 0.7429\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8457 - accuracy: 0.7587 - val_loss: 0.8819 - val_accuracy: 0.7452\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8368 - accuracy: 0.7622 - val_loss: 0.8772 - val_accuracy: 0.7449\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8292 - accuracy: 0.7639 - val_loss: 0.8802 - val_accuracy: 0.7453\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8226 - accuracy: 0.7670 - val_loss: 0.8706 - val_accuracy: 0.7474\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8137 - accuracy: 0.7679 - val_loss: 0.8501 - val_accuracy: 0.7573\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.8062 - accuracy: 0.7722 - val_loss: 0.8650 - val_accuracy: 0.7476\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7996 - accuracy: 0.7726 - val_loss: 0.8641 - val_accuracy: 0.7472\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.7925 - accuracy: 0.7751 - val_loss: 0.8313 - val_accuracy: 0.7605\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7862 - accuracy: 0.7767 - val_loss: 0.8259 - val_accuracy: 0.7629\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7781 - accuracy: 0.7786 - val_loss: 0.8245 - val_accuracy: 0.7620\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7711 - accuracy: 0.7801 - val_loss: 0.8268 - val_accuracy: 0.7624\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7654 - accuracy: 0.7825 - val_loss: 0.8058 - val_accuracy: 0.7672\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7593 - accuracy: 0.7852 - val_loss: 0.8109 - val_accuracy: 0.7656\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7545 - accuracy: 0.7854 - val_loss: 0.7969 - val_accuracy: 0.7682\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7465 - accuracy: 0.7870 - val_loss: 0.8043 - val_accuracy: 0.7627\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7417 - accuracy: 0.7886 - val_loss: 0.7996 - val_accuracy: 0.7661\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7363 - accuracy: 0.7909 - val_loss: 0.7949 - val_accuracy: 0.7677\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7299 - accuracy: 0.7935 - val_loss: 0.7970 - val_accuracy: 0.7668\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7251 - accuracy: 0.7939 - val_loss: 0.7772 - val_accuracy: 0.7733\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7204 - accuracy: 0.7940 - val_loss: 0.7908 - val_accuracy: 0.7674\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7132 - accuracy: 0.7969 - val_loss: 0.7694 - val_accuracy: 0.7759\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7079 - accuracy: 0.7980 - val_loss: 0.7806 - val_accuracy: 0.7706\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7023 - accuracy: 0.8002 - val_loss: 0.7680 - val_accuracy: 0.7766\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6992 - accuracy: 0.8015 - val_loss: 0.7374 - val_accuracy: 0.7881\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6928 - accuracy: 0.8022 - val_loss: 0.7523 - val_accuracy: 0.7824\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6889 - accuracy: 0.8032 - val_loss: 0.7524 - val_accuracy: 0.7799\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6845 - accuracy: 0.8051 - val_loss: 0.7231 - val_accuracy: 0.7924\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6780 - accuracy: 0.8076 - val_loss: 0.7287 - val_accuracy: 0.7898\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6749 - accuracy: 0.8082 - val_loss: 0.7273 - val_accuracy: 0.7886\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6695 - accuracy: 0.8092 - val_loss: 0.7258 - val_accuracy: 0.7888\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6642 - accuracy: 0.8102 - val_loss: 0.7241 - val_accuracy: 0.7886\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6620 - accuracy: 0.8116 - val_loss: 0.7343 - val_accuracy: 0.7852\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6560 - accuracy: 0.8134 - val_loss: 0.7148 - val_accuracy: 0.7931\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6526 - accuracy: 0.8141 - val_loss: 0.7178 - val_accuracy: 0.7910\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6479 - accuracy: 0.8154 - val_loss: 0.7058 - val_accuracy: 0.7952\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6441 - accuracy: 0.8171 - val_loss: 0.7519 - val_accuracy: 0.7786\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6397 - accuracy: 0.8170 - val_loss: 0.7075 - val_accuracy: 0.7939\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6349 - accuracy: 0.8197 - val_loss: 0.6860 - val_accuracy: 0.8014\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6314 - accuracy: 0.8205 - val_loss: 0.6894 - val_accuracy: 0.8002\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6278 - accuracy: 0.8209 - val_loss: 0.6895 - val_accuracy: 0.8008\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6228 - accuracy: 0.8226 - val_loss: 0.6802 - val_accuracy: 0.8020\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6208 - accuracy: 0.8234 - val_loss: 0.7052 - val_accuracy: 0.7928\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6168 - accuracy: 0.8230 - val_loss: 0.6808 - val_accuracy: 0.8010\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6146 - accuracy: 0.8258 - val_loss: 0.6928 - val_accuracy: 0.7935\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6101 - accuracy: 0.8258 - val_loss: 0.6701 - val_accuracy: 0.8059\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6044 - accuracy: 0.8281 - val_loss: 0.6979 - val_accuracy: 0.7945\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6018 - accuracy: 0.8289 - val_loss: 0.6743 - val_accuracy: 0.8030\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5977 - accuracy: 0.8300 - val_loss: 0.6529 - val_accuracy: 0.8106\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5940 - accuracy: 0.8305 - val_loss: 0.6598 - val_accuracy: 0.8077\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5905 - accuracy: 0.8327 - val_loss: 0.6484 - val_accuracy: 0.8116\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5882 - accuracy: 0.8321 - val_loss: 0.6563 - val_accuracy: 0.8089\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5854 - accuracy: 0.8331 - val_loss: 0.6465 - val_accuracy: 0.8122\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5818 - accuracy: 0.8360 - val_loss: 0.6382 - val_accuracy: 0.8159\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5773 - accuracy: 0.8365 - val_loss: 0.6477 - val_accuracy: 0.8113\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5747 - accuracy: 0.8364 - val_loss: 0.6690 - val_accuracy: 0.8018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7931897044181824, 0.7587222456932068]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "Lambda = 0.001\n",
    "train_and_test_loop(100, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCYrrGdYyaw6"
   },
   "source": [
    "Lambda value of 0.001 overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "U9iR4q2FyGj4",
    "outputId": "74555a99-e9cd-45cd-9ed5-291caa760901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 2.5989 - accuracy: 0.1197 - val_loss: 2.3023 - val_accuracy: 0.1199\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.3666 - accuracy: 0.1737 - val_loss: 2.2869 - val_accuracy: 0.1394\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.1794 - accuracy: 0.2341 - val_loss: 2.2659 - val_accuracy: 0.1424\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.0380 - accuracy: 0.2907 - val_loss: 2.2146 - val_accuracy: 0.1744\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.9193 - accuracy: 0.3435 - val_loss: 2.1122 - val_accuracy: 0.2551\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.8180 - accuracy: 0.3883 - val_loss: 1.9996 - val_accuracy: 0.3195\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.7305 - accuracy: 0.4325 - val_loss: 1.8859 - val_accuracy: 0.3780\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6569 - accuracy: 0.4660 - val_loss: 1.7862 - val_accuracy: 0.4210\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5926 - accuracy: 0.4942 - val_loss: 1.6914 - val_accuracy: 0.4636\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5351 - accuracy: 0.5228 - val_loss: 1.5944 - val_accuracy: 0.5009\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4843 - accuracy: 0.5454 - val_loss: 1.5211 - val_accuracy: 0.5321\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4397 - accuracy: 0.5649 - val_loss: 1.4694 - val_accuracy: 0.5533\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.3980 - accuracy: 0.5816 - val_loss: 1.4318 - val_accuracy: 0.5614\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.3595 - accuracy: 0.5975 - val_loss: 1.3773 - val_accuracy: 0.5873\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.3248 - accuracy: 0.6112 - val_loss: 1.3393 - val_accuracy: 0.5988\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2924 - accuracy: 0.6206 - val_loss: 1.3188 - val_accuracy: 0.5997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.2625 - accuracy: 0.6312 - val_loss: 1.2719 - val_accuracy: 0.6242\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2334 - accuracy: 0.6407 - val_loss: 1.2399 - val_accuracy: 0.6348\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2071 - accuracy: 0.6505 - val_loss: 1.2214 - val_accuracy: 0.6434\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1823 - accuracy: 0.6583 - val_loss: 1.2077 - val_accuracy: 0.6410\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1593 - accuracy: 0.6649 - val_loss: 1.1723 - val_accuracy: 0.6570\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1363 - accuracy: 0.6735 - val_loss: 1.1446 - val_accuracy: 0.6658\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.1147 - accuracy: 0.6797 - val_loss: 1.1213 - val_accuracy: 0.6712\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0944 - accuracy: 0.6847 - val_loss: 1.1269 - val_accuracy: 0.6705\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0749 - accuracy: 0.6913 - val_loss: 1.0926 - val_accuracy: 0.6829\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0579 - accuracy: 0.6966 - val_loss: 1.0755 - val_accuracy: 0.6868\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0414 - accuracy: 0.7010 - val_loss: 1.0574 - val_accuracy: 0.6936\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0256 - accuracy: 0.7054 - val_loss: 1.0386 - val_accuracy: 0.6986\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0087 - accuracy: 0.7093 - val_loss: 1.0235 - val_accuracy: 0.7022\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9948 - accuracy: 0.7158 - val_loss: 1.0246 - val_accuracy: 0.7023\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9811 - accuracy: 0.7180 - val_loss: 0.9952 - val_accuracy: 0.7121\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9669 - accuracy: 0.7221 - val_loss: 0.9921 - val_accuracy: 0.7144\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9528 - accuracy: 0.7247 - val_loss: 0.9771 - val_accuracy: 0.7193\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9407 - accuracy: 0.7295 - val_loss: 0.9684 - val_accuracy: 0.7181\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9289 - accuracy: 0.7326 - val_loss: 0.9549 - val_accuracy: 0.7231\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9170 - accuracy: 0.7356 - val_loss: 0.9630 - val_accuracy: 0.7173\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9078 - accuracy: 0.7375 - val_loss: 0.9291 - val_accuracy: 0.7301\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8956 - accuracy: 0.7410 - val_loss: 0.9240 - val_accuracy: 0.7310\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.8861 - accuracy: 0.7433 - val_loss: 0.9159 - val_accuracy: 0.7328\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8755 - accuracy: 0.7469 - val_loss: 0.9226 - val_accuracy: 0.7284\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8665 - accuracy: 0.7490 - val_loss: 0.8987 - val_accuracy: 0.7383\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8562 - accuracy: 0.7512 - val_loss: 0.8960 - val_accuracy: 0.7368\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8460 - accuracy: 0.7549 - val_loss: 0.8868 - val_accuracy: 0.7404\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8387 - accuracy: 0.7580 - val_loss: 0.8697 - val_accuracy: 0.7468\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8288 - accuracy: 0.7594 - val_loss: 0.8619 - val_accuracy: 0.7492\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8198 - accuracy: 0.7622 - val_loss: 0.8546 - val_accuracy: 0.7469\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8130 - accuracy: 0.7638 - val_loss: 0.8528 - val_accuracy: 0.7488\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8043 - accuracy: 0.7678 - val_loss: 0.8479 - val_accuracy: 0.7516\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7965 - accuracy: 0.7680 - val_loss: 0.8377 - val_accuracy: 0.7550\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7885 - accuracy: 0.7698 - val_loss: 0.8304 - val_accuracy: 0.7582\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7813 - accuracy: 0.7731 - val_loss: 0.8275 - val_accuracy: 0.7562\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7741 - accuracy: 0.7756 - val_loss: 0.8250 - val_accuracy: 0.7564\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7658 - accuracy: 0.7772 - val_loss: 0.8020 - val_accuracy: 0.7657\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7598 - accuracy: 0.7784 - val_loss: 0.8600 - val_accuracy: 0.7397\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7544 - accuracy: 0.7808 - val_loss: 0.7974 - val_accuracy: 0.7657\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7462 - accuracy: 0.7824 - val_loss: 0.7907 - val_accuracy: 0.7661\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7407 - accuracy: 0.7843 - val_loss: 0.7772 - val_accuracy: 0.7710\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7327 - accuracy: 0.7869 - val_loss: 0.7870 - val_accuracy: 0.7682\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7274 - accuracy: 0.7882 - val_loss: 0.7621 - val_accuracy: 0.7787\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7204 - accuracy: 0.7911 - val_loss: 0.7666 - val_accuracy: 0.7750\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7166 - accuracy: 0.7920 - val_loss: 0.7617 - val_accuracy: 0.7742\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7086 - accuracy: 0.7940 - val_loss: 0.7557 - val_accuracy: 0.7764\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7042 - accuracy: 0.7959 - val_loss: 0.7663 - val_accuracy: 0.7761\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6987 - accuracy: 0.7969 - val_loss: 0.7583 - val_accuracy: 0.7764\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6935 - accuracy: 0.7974 - val_loss: 0.7403 - val_accuracy: 0.7836\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6884 - accuracy: 0.8005 - val_loss: 0.7380 - val_accuracy: 0.7849\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6828 - accuracy: 0.8010 - val_loss: 0.7353 - val_accuracy: 0.7824\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6761 - accuracy: 0.8030 - val_loss: 0.7362 - val_accuracy: 0.7811\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6729 - accuracy: 0.8044 - val_loss: 0.7227 - val_accuracy: 0.7869\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6663 - accuracy: 0.8057 - val_loss: 0.7164 - val_accuracy: 0.7892\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6616 - accuracy: 0.8074 - val_loss: 0.7221 - val_accuracy: 0.7872\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6566 - accuracy: 0.8096 - val_loss: 0.7156 - val_accuracy: 0.7886\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6503 - accuracy: 0.8110 - val_loss: 0.7056 - val_accuracy: 0.7932\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6461 - accuracy: 0.8132 - val_loss: 0.7023 - val_accuracy: 0.7937\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6419 - accuracy: 0.8131 - val_loss: 0.7215 - val_accuracy: 0.7851\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6366 - accuracy: 0.8152 - val_loss: 0.7038 - val_accuracy: 0.7930\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6333 - accuracy: 0.8154 - val_loss: 0.7152 - val_accuracy: 0.7882\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6297 - accuracy: 0.8169 - val_loss: 0.7016 - val_accuracy: 0.7915\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6240 - accuracy: 0.8183 - val_loss: 0.6847 - val_accuracy: 0.7993\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6204 - accuracy: 0.8184 - val_loss: 0.7015 - val_accuracy: 0.7928\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6170 - accuracy: 0.8201 - val_loss: 0.6818 - val_accuracy: 0.7976\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6127 - accuracy: 0.8221 - val_loss: 0.6816 - val_accuracy: 0.7979\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6080 - accuracy: 0.8231 - val_loss: 0.6691 - val_accuracy: 0.8029\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6018 - accuracy: 0.8254 - val_loss: 0.6608 - val_accuracy: 0.8054\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5999 - accuracy: 0.8254 - val_loss: 0.7009 - val_accuracy: 0.7873\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5982 - accuracy: 0.8258 - val_loss: 0.6731 - val_accuracy: 0.8013\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5942 - accuracy: 0.8273 - val_loss: 0.6694 - val_accuracy: 0.8019\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5898 - accuracy: 0.8296 - val_loss: 0.6653 - val_accuracy: 0.8014\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5852 - accuracy: 0.8296 - val_loss: 0.6620 - val_accuracy: 0.8039\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5807 - accuracy: 0.8301 - val_loss: 0.6670 - val_accuracy: 0.8027\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5760 - accuracy: 0.8335 - val_loss: 0.6516 - val_accuracy: 0.8072\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5726 - accuracy: 0.8354 - val_loss: 0.6774 - val_accuracy: 0.7988\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5710 - accuracy: 0.8349 - val_loss: 0.6543 - val_accuracy: 0.8066\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5666 - accuracy: 0.8356 - val_loss: 0.6371 - val_accuracy: 0.8129\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5627 - accuracy: 0.8386 - val_loss: 0.6387 - val_accuracy: 0.8114\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5604 - accuracy: 0.8385 - val_loss: 0.6497 - val_accuracy: 0.8074\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.5555 - accuracy: 0.8410 - val_loss: 0.6208 - val_accuracy: 0.8180\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 3s 66ms/step - loss: 0.5512 - accuracy: 0.8406 - val_loss: 0.6425 - val_accuracy: 0.8098\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 3s 68ms/step - loss: 0.5507 - accuracy: 0.8421 - val_loss: 0.6522 - val_accuracy: 0.8054\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.5467 - accuracy: 0.8426 - val_loss: 0.6316 - val_accuracy: 0.8123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7571341395378113, 0.7736111283302307]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "Lambda = 0.0001\n",
    "train_and_test_loop(100, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixHhorIuyqE5"
   },
   "source": [
    "Lambda value of 0.0001 also overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FYXOqbsxyQqd",
    "outputId": "db846923-abd0-4d27-8bc2-412dc9508148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 2.7550 - accuracy: 0.1200 - val_loss: 2.4837 - val_accuracy: 0.0998\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.4790 - accuracy: 0.1824 - val_loss: 2.4734 - val_accuracy: 0.1158\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.2880 - accuracy: 0.2497 - val_loss: 2.4340 - val_accuracy: 0.1573\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.1494 - accuracy: 0.3107 - val_loss: 2.3705 - val_accuracy: 0.2073\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.0364 - accuracy: 0.3628 - val_loss: 2.2724 - val_accuracy: 0.2645\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.9397 - accuracy: 0.4106 - val_loss: 2.1580 - val_accuracy: 0.3297\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.8546 - accuracy: 0.4501 - val_loss: 2.0503 - val_accuracy: 0.3823\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.7827 - accuracy: 0.4827 - val_loss: 1.9419 - val_accuracy: 0.4266\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.7174 - accuracy: 0.5134 - val_loss: 1.8395 - val_accuracy: 0.4727\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6599 - accuracy: 0.5379 - val_loss: 1.7566 - val_accuracy: 0.5060\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6093 - accuracy: 0.5595 - val_loss: 1.6948 - val_accuracy: 0.5276\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5630 - accuracy: 0.5765 - val_loss: 1.6129 - val_accuracy: 0.5615\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5199 - accuracy: 0.5917 - val_loss: 1.5838 - val_accuracy: 0.5652\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4811 - accuracy: 0.6067 - val_loss: 1.5182 - val_accuracy: 0.5911\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4455 - accuracy: 0.6180 - val_loss: 1.4733 - val_accuracy: 0.6081\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4112 - accuracy: 0.6284 - val_loss: 1.4410 - val_accuracy: 0.6162\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.3786 - accuracy: 0.6386 - val_loss: 1.4102 - val_accuracy: 0.6255\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.3492 - accuracy: 0.6483 - val_loss: 1.3717 - val_accuracy: 0.6381\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.3212 - accuracy: 0.6537 - val_loss: 1.3453 - val_accuracy: 0.6458\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.2947 - accuracy: 0.6614 - val_loss: 1.3185 - val_accuracy: 0.6545\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.2701 - accuracy: 0.6686 - val_loss: 1.2933 - val_accuracy: 0.6620\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2470 - accuracy: 0.6748 - val_loss: 1.2724 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2240 - accuracy: 0.6813 - val_loss: 1.2579 - val_accuracy: 0.6690\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.2032 - accuracy: 0.6853 - val_loss: 1.2340 - val_accuracy: 0.6744\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.1841 - accuracy: 0.6915 - val_loss: 1.2189 - val_accuracy: 0.6816\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1649 - accuracy: 0.6954 - val_loss: 1.1845 - val_accuracy: 0.6898\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1462 - accuracy: 0.7006 - val_loss: 1.1720 - val_accuracy: 0.6924\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1295 - accuracy: 0.7069 - val_loss: 1.1585 - val_accuracy: 0.6958\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1120 - accuracy: 0.7092 - val_loss: 1.1420 - val_accuracy: 0.7014\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0960 - accuracy: 0.7137 - val_loss: 1.1360 - val_accuracy: 0.6990\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0801 - accuracy: 0.7196 - val_loss: 1.1165 - val_accuracy: 0.7025\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0663 - accuracy: 0.7214 - val_loss: 1.0985 - val_accuracy: 0.7109\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0533 - accuracy: 0.7249 - val_loss: 1.0839 - val_accuracy: 0.7153\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0379 - accuracy: 0.7278 - val_loss: 1.0816 - val_accuracy: 0.7145\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0255 - accuracy: 0.7310 - val_loss: 1.0645 - val_accuracy: 0.7195\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0124 - accuracy: 0.7356 - val_loss: 1.0514 - val_accuracy: 0.7253\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9997 - accuracy: 0.7384 - val_loss: 1.0357 - val_accuracy: 0.7248\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.9895 - accuracy: 0.7423 - val_loss: 1.0395 - val_accuracy: 0.7218\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9758 - accuracy: 0.7444 - val_loss: 1.0302 - val_accuracy: 0.7248\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9651 - accuracy: 0.7480 - val_loss: 1.0103 - val_accuracy: 0.7295\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9542 - accuracy: 0.7496 - val_loss: 1.0056 - val_accuracy: 0.7285\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9443 - accuracy: 0.7519 - val_loss: 0.9857 - val_accuracy: 0.7392\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9337 - accuracy: 0.7533 - val_loss: 0.9838 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9239 - accuracy: 0.7562 - val_loss: 0.9730 - val_accuracy: 0.7376\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9138 - accuracy: 0.7597 - val_loss: 0.9583 - val_accuracy: 0.7464\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9027 - accuracy: 0.7621 - val_loss: 0.9524 - val_accuracy: 0.7430\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8960 - accuracy: 0.7630 - val_loss: 0.9490 - val_accuracy: 0.7456\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8851 - accuracy: 0.7671 - val_loss: 0.9348 - val_accuracy: 0.7508\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8775 - accuracy: 0.7673 - val_loss: 0.9259 - val_accuracy: 0.7513\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8683 - accuracy: 0.7692 - val_loss: 0.9104 - val_accuracy: 0.7561\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8581 - accuracy: 0.7738 - val_loss: 0.9123 - val_accuracy: 0.7544\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8495 - accuracy: 0.7749 - val_loss: 0.8994 - val_accuracy: 0.7592\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.8415 - accuracy: 0.7765 - val_loss: 0.8877 - val_accuracy: 0.7615\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8335 - accuracy: 0.7791 - val_loss: 0.8945 - val_accuracy: 0.7570\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8264 - accuracy: 0.7797 - val_loss: 0.8637 - val_accuracy: 0.7687\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8185 - accuracy: 0.7818 - val_loss: 0.8772 - val_accuracy: 0.7623\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8109 - accuracy: 0.7830 - val_loss: 0.8566 - val_accuracy: 0.7685\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8019 - accuracy: 0.7858 - val_loss: 0.8628 - val_accuracy: 0.7646\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7947 - accuracy: 0.7886 - val_loss: 0.8440 - val_accuracy: 0.7731\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7878 - accuracy: 0.7897 - val_loss: 0.8439 - val_accuracy: 0.7708\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7817 - accuracy: 0.7912 - val_loss: 0.8532 - val_accuracy: 0.7662\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7735 - accuracy: 0.7939 - val_loss: 0.8267 - val_accuracy: 0.7753\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7668 - accuracy: 0.7964 - val_loss: 0.8223 - val_accuracy: 0.7782\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7616 - accuracy: 0.7963 - val_loss: 0.8169 - val_accuracy: 0.7756\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7547 - accuracy: 0.7999 - val_loss: 0.8225 - val_accuracy: 0.7760\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7477 - accuracy: 0.7998 - val_loss: 0.8099 - val_accuracy: 0.7816\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7422 - accuracy: 0.8023 - val_loss: 0.7974 - val_accuracy: 0.7829\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7369 - accuracy: 0.8032 - val_loss: 0.7989 - val_accuracy: 0.7813\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7286 - accuracy: 0.8049 - val_loss: 0.8014 - val_accuracy: 0.7809\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7232 - accuracy: 0.8064 - val_loss: 0.7819 - val_accuracy: 0.7868\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7177 - accuracy: 0.8079 - val_loss: 0.7879 - val_accuracy: 0.7828\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7130 - accuracy: 0.8090 - val_loss: 0.7805 - val_accuracy: 0.7887\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7056 - accuracy: 0.8101 - val_loss: 0.7758 - val_accuracy: 0.7863\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6991 - accuracy: 0.8133 - val_loss: 0.7610 - val_accuracy: 0.7914\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.6938 - accuracy: 0.8155 - val_loss: 0.7525 - val_accuracy: 0.7947\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6883 - accuracy: 0.8149 - val_loss: 0.7765 - val_accuracy: 0.7836\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6838 - accuracy: 0.8175 - val_loss: 0.7579 - val_accuracy: 0.7896\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6781 - accuracy: 0.8181 - val_loss: 0.7572 - val_accuracy: 0.7896\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6726 - accuracy: 0.8208 - val_loss: 0.7369 - val_accuracy: 0.7978\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6675 - accuracy: 0.8209 - val_loss: 0.7401 - val_accuracy: 0.7962\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6607 - accuracy: 0.8234 - val_loss: 0.7271 - val_accuracy: 0.7997\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6550 - accuracy: 0.8238 - val_loss: 0.7286 - val_accuracy: 0.7995\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6504 - accuracy: 0.8262 - val_loss: 0.7137 - val_accuracy: 0.8071\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6472 - accuracy: 0.8265 - val_loss: 0.7161 - val_accuracy: 0.8042\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6403 - accuracy: 0.8269 - val_loss: 0.7258 - val_accuracy: 0.7980\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6368 - accuracy: 0.8296 - val_loss: 0.7142 - val_accuracy: 0.8031\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.6320 - accuracy: 0.8301 - val_loss: 0.6993 - val_accuracy: 0.8084\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6273 - accuracy: 0.8315 - val_loss: 0.7031 - val_accuracy: 0.8055\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6226 - accuracy: 0.8325 - val_loss: 0.6958 - val_accuracy: 0.8076\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.6180 - accuracy: 0.8329 - val_loss: 0.7025 - val_accuracy: 0.8055\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6142 - accuracy: 0.8344 - val_loss: 0.6742 - val_accuracy: 0.8151\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.6095 - accuracy: 0.8366 - val_loss: 0.6764 - val_accuracy: 0.8138\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.6047 - accuracy: 0.8363 - val_loss: 0.7030 - val_accuracy: 0.8046\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6005 - accuracy: 0.8381 - val_loss: 0.6904 - val_accuracy: 0.8055\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5956 - accuracy: 0.8405 - val_loss: 0.6850 - val_accuracy: 0.8071\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5935 - accuracy: 0.8404 - val_loss: 0.6790 - val_accuracy: 0.8104\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5891 - accuracy: 0.8413 - val_loss: 0.6747 - val_accuracy: 0.8128\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.5854 - accuracy: 0.8420 - val_loss: 0.6595 - val_accuracy: 0.8186\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5805 - accuracy: 0.8424 - val_loss: 0.6573 - val_accuracy: 0.8172\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5756 - accuracy: 0.8436 - val_loss: 0.6507 - val_accuracy: 0.8195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7857251763343811, 0.773888885974884]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "Lambda = 0.01\n",
    "train_and_test_loop(100, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Kh-4D9gEzpDi",
    "outputId": "75d6bd89-ecdb-44a5-c0bc-5632f85f21b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 4.2400 - accuracy: 0.1248 - val_loss: 3.8451 - val_accuracy: 0.1098\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 3.7161 - accuracy: 0.1861 - val_loss: 3.6006 - val_accuracy: 0.1260\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 3.3056 - accuracy: 0.2530 - val_loss: 3.3778 - val_accuracy: 0.1520\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.9812 - accuracy: 0.3102 - val_loss: 3.1518 - val_accuracy: 0.1972\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.7111 - accuracy: 0.3629 - val_loss: 2.9329 - val_accuracy: 0.2467\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.4800 - accuracy: 0.4102 - val_loss: 2.6892 - val_accuracy: 0.3207\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 2.2859 - accuracy: 0.4481 - val_loss: 2.4836 - val_accuracy: 0.3629\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 2.1194 - accuracy: 0.4817 - val_loss: 2.2955 - val_accuracy: 0.4066\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.9762 - accuracy: 0.5131 - val_loss: 2.1320 - val_accuracy: 0.4517\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.8528 - accuracy: 0.5342 - val_loss: 1.9949 - val_accuracy: 0.4869\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.7444 - accuracy: 0.5577 - val_loss: 1.8737 - val_accuracy: 0.5197\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.6502 - accuracy: 0.5784 - val_loss: 1.7705 - val_accuracy: 0.5439\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5648 - accuracy: 0.5937 - val_loss: 1.6899 - val_accuracy: 0.5696\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.4899 - accuracy: 0.6118 - val_loss: 1.6229 - val_accuracy: 0.5818\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4240 - accuracy: 0.6244 - val_loss: 1.5603 - val_accuracy: 0.5987\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 1.3652 - accuracy: 0.6376 - val_loss: 1.4884 - val_accuracy: 0.6179\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.3148 - accuracy: 0.6473 - val_loss: 1.4374 - val_accuracy: 0.6260\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2693 - accuracy: 0.6562 - val_loss: 1.3784 - val_accuracy: 0.6456\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2283 - accuracy: 0.6658 - val_loss: 1.3376 - val_accuracy: 0.6528\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1925 - accuracy: 0.6741 - val_loss: 1.3139 - val_accuracy: 0.6589\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1610 - accuracy: 0.6798 - val_loss: 1.2807 - val_accuracy: 0.6645\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1327 - accuracy: 0.6869 - val_loss: 1.2429 - val_accuracy: 0.6728\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1066 - accuracy: 0.6913 - val_loss: 1.2085 - val_accuracy: 0.6810\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0836 - accuracy: 0.6990 - val_loss: 1.1850 - val_accuracy: 0.6827\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0613 - accuracy: 0.7029 - val_loss: 1.1494 - val_accuracy: 0.6937\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0431 - accuracy: 0.7086 - val_loss: 1.1325 - val_accuracy: 0.6943\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0259 - accuracy: 0.7129 - val_loss: 1.1053 - val_accuracy: 0.7006\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.0115 - accuracy: 0.7160 - val_loss: 1.0741 - val_accuracy: 0.7067\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9951 - accuracy: 0.7205 - val_loss: 1.0517 - val_accuracy: 0.7139\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9814 - accuracy: 0.7240 - val_loss: 1.0457 - val_accuracy: 0.7093\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9683 - accuracy: 0.7281 - val_loss: 1.0275 - val_accuracy: 0.7107\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9549 - accuracy: 0.7305 - val_loss: 1.0007 - val_accuracy: 0.7192\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9445 - accuracy: 0.7348 - val_loss: 0.9869 - val_accuracy: 0.7211\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9326 - accuracy: 0.7381 - val_loss: 0.9768 - val_accuracy: 0.7234\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9214 - accuracy: 0.7398 - val_loss: 0.9492 - val_accuracy: 0.7319\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9087 - accuracy: 0.7444 - val_loss: 0.9565 - val_accuracy: 0.7281\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8993 - accuracy: 0.7451 - val_loss: 0.9365 - val_accuracy: 0.7334\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8882 - accuracy: 0.7503 - val_loss: 0.9473 - val_accuracy: 0.7265\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.8785 - accuracy: 0.7530 - val_loss: 0.9195 - val_accuracy: 0.7388\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8693 - accuracy: 0.7559 - val_loss: 0.9033 - val_accuracy: 0.7424\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8591 - accuracy: 0.7589 - val_loss: 0.9013 - val_accuracy: 0.7423\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8510 - accuracy: 0.7610 - val_loss: 0.8833 - val_accuracy: 0.7493\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.8428 - accuracy: 0.7626 - val_loss: 0.8755 - val_accuracy: 0.7494\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.8363 - accuracy: 0.7639 - val_loss: 0.8697 - val_accuracy: 0.7533\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.8259 - accuracy: 0.7664 - val_loss: 0.8709 - val_accuracy: 0.7491\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8189 - accuracy: 0.7696 - val_loss: 0.8599 - val_accuracy: 0.7512\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8106 - accuracy: 0.7713 - val_loss: 0.8555 - val_accuracy: 0.7544\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8033 - accuracy: 0.7735 - val_loss: 0.8600 - val_accuracy: 0.7513\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7950 - accuracy: 0.7755 - val_loss: 0.8440 - val_accuracy: 0.7571\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7877 - accuracy: 0.7782 - val_loss: 0.8322 - val_accuracy: 0.7596\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7794 - accuracy: 0.7804 - val_loss: 0.8236 - val_accuracy: 0.7642\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.7724 - accuracy: 0.7825 - val_loss: 0.8176 - val_accuracy: 0.7655\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7659 - accuracy: 0.7851 - val_loss: 0.8064 - val_accuracy: 0.7666\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7588 - accuracy: 0.7849 - val_loss: 0.8167 - val_accuracy: 0.7652\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7516 - accuracy: 0.7880 - val_loss: 0.7931 - val_accuracy: 0.7744\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7479 - accuracy: 0.7883 - val_loss: 0.7916 - val_accuracy: 0.7725\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7403 - accuracy: 0.7920 - val_loss: 0.7885 - val_accuracy: 0.7732\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7347 - accuracy: 0.7927 - val_loss: 0.7751 - val_accuracy: 0.7778\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7263 - accuracy: 0.7953 - val_loss: 0.7692 - val_accuracy: 0.7800\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7201 - accuracy: 0.7968 - val_loss: 0.7706 - val_accuracy: 0.7814\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7144 - accuracy: 0.7975 - val_loss: 0.7570 - val_accuracy: 0.7824\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7086 - accuracy: 0.7990 - val_loss: 0.7618 - val_accuracy: 0.7793\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.7045 - accuracy: 0.8020 - val_loss: 0.7656 - val_accuracy: 0.7782\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6973 - accuracy: 0.8044 - val_loss: 0.7471 - val_accuracy: 0.7868\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6931 - accuracy: 0.8042 - val_loss: 0.7588 - val_accuracy: 0.7792\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6866 - accuracy: 0.8065 - val_loss: 0.7500 - val_accuracy: 0.7842\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6830 - accuracy: 0.8082 - val_loss: 0.7312 - val_accuracy: 0.7899\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6759 - accuracy: 0.8092 - val_loss: 0.7157 - val_accuracy: 0.7968\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 0.6709 - accuracy: 0.8109 - val_loss: 0.7275 - val_accuracy: 0.7902\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 0.6662 - accuracy: 0.8118 - val_loss: 0.7174 - val_accuracy: 0.7934\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6619 - accuracy: 0.8125 - val_loss: 0.7182 - val_accuracy: 0.7939\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6567 - accuracy: 0.8149 - val_loss: 0.7144 - val_accuracy: 0.7954\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6534 - accuracy: 0.8159 - val_loss: 0.7250 - val_accuracy: 0.7897\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6463 - accuracy: 0.8179 - val_loss: 0.7061 - val_accuracy: 0.7995\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6439 - accuracy: 0.8177 - val_loss: 0.7287 - val_accuracy: 0.7879\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.6388 - accuracy: 0.8201 - val_loss: 0.7038 - val_accuracy: 0.7979\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6364 - accuracy: 0.8203 - val_loss: 0.7085 - val_accuracy: 0.7959\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6306 - accuracy: 0.8231 - val_loss: 0.6837 - val_accuracy: 0.8030\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6267 - accuracy: 0.8235 - val_loss: 0.6978 - val_accuracy: 0.7972\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6234 - accuracy: 0.8255 - val_loss: 0.6880 - val_accuracy: 0.8004\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6185 - accuracy: 0.8270 - val_loss: 0.6743 - val_accuracy: 0.8056\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6163 - accuracy: 0.8268 - val_loss: 0.6872 - val_accuracy: 0.8023\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6083 - accuracy: 0.8304 - val_loss: 0.7006 - val_accuracy: 0.7946\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6041 - accuracy: 0.8317 - val_loss: 0.6732 - val_accuracy: 0.8046\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6006 - accuracy: 0.8319 - val_loss: 0.6915 - val_accuracy: 0.7970\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5980 - accuracy: 0.8314 - val_loss: 0.6584 - val_accuracy: 0.8110\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5954 - accuracy: 0.8330 - val_loss: 0.6815 - val_accuracy: 0.8017\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5906 - accuracy: 0.8349 - val_loss: 0.6613 - val_accuracy: 0.8088\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5868 - accuracy: 0.8367 - val_loss: 0.6427 - val_accuracy: 0.8169\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5839 - accuracy: 0.8377 - val_loss: 0.6491 - val_accuracy: 0.8150\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5788 - accuracy: 0.8382 - val_loss: 0.6358 - val_accuracy: 0.8173\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5745 - accuracy: 0.8402 - val_loss: 0.6382 - val_accuracy: 0.8162\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5711 - accuracy: 0.8411 - val_loss: 0.6285 - val_accuracy: 0.8199\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5678 - accuracy: 0.8419 - val_loss: 0.6379 - val_accuracy: 0.8167\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5653 - accuracy: 0.8422 - val_loss: 0.6899 - val_accuracy: 0.7973\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5618 - accuracy: 0.8426 - val_loss: 0.6211 - val_accuracy: 0.8234\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5576 - accuracy: 0.8451 - val_loss: 0.6232 - val_accuracy: 0.8216\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5544 - accuracy: 0.8454 - val_loss: 0.6235 - val_accuracy: 0.8219\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5531 - accuracy: 0.8465 - val_loss: 0.6224 - val_accuracy: 0.8224\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5479 - accuracy: 0.8475 - val_loss: 0.6308 - val_accuracy: 0.8183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.760826051235199, 0.7746111154556274]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "Lambda = 0.1\n",
    "train_and_test_loop(100, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xTSPVV9X1KDR"
   },
   "source": [
    "Lambda seems not to be making much difference to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mK5IZk5U1rvN"
   },
   "source": [
    "#Choosing the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8hBltRt1wgM"
   },
   "source": [
    "The best model seems to be the model with 5 layers of 4 hidden layers with 100 neurons each and output layer with 10 neurons having a learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "rAKE85r52EJp",
    "outputId": "6e20d64c-06f8-400d-ccf4-c613a13f7150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 135,450\n",
      "Trainable params: 134,630\n",
      "Non-trainable params: 820\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Best model summary\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmu-iJBw44Rw"
   },
   "source": [
    "#Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjH7xfn17rcc"
   },
   "outputs": [],
   "source": [
    "#Opening file as read only\n",
    "data_SVHN = h5py.File('/content/drive/My Drive/GL dataset/SVHN_single_grey1.h5' , 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HeyybtbH7ueY"
   },
   "outputs": [],
   "source": [
    "#Loading target value of test\n",
    "\n",
    "y_target = data_SVHN ['y_test'][:]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FOWOQv028JfX",
    "outputId": "477f6e28-48be-4b67-8ce6-e1e86c105186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method File.close of <HDF5 file \"SVHN_single_grey1.h5\" (mode r)>>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Close the file\n",
    "data_SVHN.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9q3z52y6GhF"
   },
   "outputs": [],
   "source": [
    "Y_pred_cls = model4.predict_classes(X_test, batch_size=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "JqT8MxZB84xa",
    "outputId": "634d1435-f270-4acc-9a36-c085f5d14f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1448   59   20   30   36   36   46   34   40   65]\n",
      " [  22 1546   22   36   55   21   15   70   25   16]\n",
      " [  22   51 1424   25   27   34   17  118   29   56]\n",
      " [  26   83   55 1159   24  212   25   56   50   29]\n",
      " [  25   78   38   27 1477   45   42   20   22   38]\n",
      " [  26   28   20   69   18 1455   51   16   53   32]\n",
      " [  52   45   18   20   59  110 1419   16   77   16]\n",
      " [  25   77   63   27   11   26   13 1524   16   26]\n",
      " [  48   63   30   42   37  104  110   15 1283   80]\n",
      " [  69   63   27   41   23  101   21   38   52 1369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1814\n",
      "           1       0.74      0.85      0.79      1828\n",
      "           2       0.83      0.79      0.81      1803\n",
      "           3       0.79      0.67      0.73      1719\n",
      "           4       0.84      0.82      0.83      1812\n",
      "           5       0.68      0.82      0.74      1768\n",
      "           6       0.81      0.77      0.79      1832\n",
      "           7       0.80      0.84      0.82      1808\n",
      "           8       0.78      0.71      0.74      1812\n",
      "           9       0.79      0.76      0.78      1804\n",
      "\n",
      "    accuracy                           0.78     18000\n",
      "   macro avg       0.79      0.78      0.78     18000\n",
      "weighted avg       0.79      0.78      0.78     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_target, Y_pred_cls))\n",
    "\n",
    "print(classification_report(y_target, Y_pred_cls))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project - Neural Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
